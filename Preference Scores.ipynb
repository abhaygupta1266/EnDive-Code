{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RXAKjM9trN-Z"},"outputs":[],"source":["#GPT-4o\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install openai==0.28\n","\n","import os\n","import re\n","import csv\n","import pandas as pd\n","import openai\n","from tqdm import tqdm\n","\n","\n","openai.api_key = \"API-KEY\"\n","\n","DATASET_PATHS = {\n","    \"FOLIO(1000)\":               \"aligned_folio1000.csv\",\n","    \"BoolQ (1000)\":              \"GLUE + SuperGLUE/aligned_boolq_1000.csv\",\n","    \"COPA (500)\":                \"GLUE + SuperGLUE/aligned_copa_500.csv\",\n","    \"MultiRC (1000)\":            \"GLUE + SuperGLUE/aligned_multirc_1000.csv\",\n","    \"SST-2 (1000)\":              \"GLUE + SuperGLUE/aligned_sst-2_1000.csv\",\n","    \"WSC (659)\":                 \"GLUE + SuperGLUE/aligned_wsc_659.csv\",\n","    \"GSM8K(1000)\":               \"aligned_gsm8k1000.csv\",\n","    \"HumanEVAL(164)\":            \"aligned_humaneval164.csv\",\n","    \"Logic Bench MCQ(480)\":      \"aligned_logic_bench_mcq480.csv\",\n","    \"Logic Bench YN(500)\":       \"aligned_logic_bench_yn500.csv\",\n","    \"MBPP(374)\":                 \"aligned_mbpp374.csv\",\n","    \"SVAMP(700)\":                \"aligned_svamp700.csv\",\n","}\n","\n","DIALECTS = [\"AAVE\", \"ChcE\", \"CollSgE\", \"IndE\", \"JamE\"]\n","\n","BASE_INPUT_DIR = \"/content/drive/MyDrive/!!Multi-AAVENUE/Aligned Translations\"\n","BASE_OUTPUT_DIR = \"/content/drive/MyDrive/!!Multi-AAVENUE/Metrics/Preference Scores/GPT 4o\"\n","\n","COT_PROMPT = \"\"\"\n","You are an expert linguist with a strong command of {dialect}.\n","\n","You are given:\n","1) **Original Text (SAE)** – a standard American English version for reference.\n","2) **Translation A** – a version in the {dialect} dialect.\n","3) **Translation B** – another version in the {dialect} dialect.\n","\n","Your task: Decide which translation is better **in the context of the {dialect} dialect** with respect to:\n","- Fluency (grammar, syntax, word choice, overall naturalness in {dialect})\n","- Accuracy (faithfulness to the original meaning, but expressed naturally in {dialect})\n","- Readability (cohesion, clarity, and flow in {dialect})\n","- Cultural appropriateness (if relevant to {dialect})\n","\n","Provide a detailed chain-of-thought (reasoning) as to how you weigh these factors.\n","Then conclude with one final line in the exact format:\n","**\"Final preference score: X\"**\n","(where **X = 1** if you prefer Translation A, or **X = 2** if you prefer Translation B).\n","\n","Make sure you **reveal** your full thought process, then **end** with:\n","Final preference score: X\n","\"\"\"\n","\n","def get_preference_score(original_text: str, trans_a: str, trans_b: str, dialect: str):\n","    \"\"\"\n","    Returns: (model_full_response, preference_int)\n","       model_full_response: the entire chain-of-thought + final line\n","       preference_int: 1 or 2 if found, else -1\n","    \"\"\"\n","    try:\n","        user_content = f\"\"\"Original Text (SAE):\n","{original_text}\n","\n","Translation A ({dialect}):\n","{trans_a}\n","\n","Translation B ({dialect}):\n","{trans_b}\n","\n","Please show your detailed reasoning focusing on {dialect} usage, then conclude with:\n","Final preference score: X\n","\"\"\"\n","\n","        # Call ChatCompletion\n","        response = openai.ChatCompletion.create(\n","            model=\"gpt-4o\",  # or another GPT-4 variant\n","            messages=[\n","                {\"role\": \"system\", \"content\": COT_PROMPT.format(dialect=dialect)},\n","                {\"role\": \"user\", \"content\": user_content}\n","            ],\n","            temperature=0.0\n","        )\n","\n","        result_text = response[\"choices\"][0][\"message\"][\"content\"].strip()\n","\n","        # Parse final preference\n","        match = re.search(r\"Final preference score:\\s*([12])\", result_text)\n","        if match:\n","            pref = int(match.group(1))\n","        else:\n","            pref = -1\n","\n","        return (result_text, pref)\n","    except Exception as e:\n","        print(f\"Error retrieving preference: {e}\")\n","        return (\"\", -1)\n","\n","def process_dataset(dialect: str, ds_name: str):\n","    \"\"\"\n","    1) Build the input CSV path by combining the base path, the dialect, and the subpath from DATASET_PATHS[ds_name].\n","    2) Read the CSV -> columns: \"Original\", \"Filtered GPT 4o\" (Translation A), \"Filtered Multi-VALUE\" (Translation B).\n","    3) For each row, call get_preference_score(), capturing the entire chain-of-thought plus final line.\n","    4) Write results to CSV:\n","       [Original, Translation A, Translation B, Chain-of-Thought & Decision, Preference Score]\n","    5) Summarize how many times the model picked 1 vs 2 in a .txt file.\n","    \"\"\"\n","    if ds_name not in DATASET_PATHS:\n","        print(f\"[!] No path mapped for dataset: {ds_name}\")\n","        return\n","    subpath = DATASET_PATHS[ds_name]\n","\n","    input_path = os.path.join(BASE_INPUT_DIR, dialect, subpath)\n","\n","    if not os.path.isfile(input_path):\n","        print(f\"[!] File not found: {input_path} - skipping.\")\n","        return\n","\n","    df = pd.read_csv(input_path, encoding=\"utf-8\")\n","\n","    out_folder = os.path.join(BASE_OUTPUT_DIR, dialect, ds_name)\n","    os.makedirs(out_folder, exist_ok=True)\n","\n","    csv_out_path = os.path.join(out_folder, f\"{ds_name}_preference.csv\")\n","    txt_out_path = os.path.join(out_folder, f\"{ds_name}_preference_summary.txt\")\n","\n","    all_prefs = []\n","\n","    fieldnames = [\n","        \"Original\",\n","        \"Translation A\",\n","        \"Translation B\",\n","        \"Chain-of-Thought & Decision\",\n","        \"Preference Score\"\n","    ]\n","    with open(csv_out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","        writer = csv.DictWriter(f, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"{ds_name} - {dialect}\"):\n","        original_text = str(row.get(\"Original\", \"\")).strip()\n","        trans_a = str(row.get(\"Filtered GPT 4o\", \"\")).strip()\n","        trans_b = str(row.get(\"Filtered Multi-VALUE\", \"\")).strip()\n","\n","        if not trans_a or not trans_b:\n","            chain_of_thought = \"(N/A: missing data)\"\n","            pref = -1\n","        else:\n","            chain_of_thought, pref = get_preference_score(\n","                original_text, trans_a, trans_b, dialect\n","            )\n","\n","        all_prefs.append(pref)\n","\n","        # Write row to CSV\n","        row_dict = {\n","            \"Original\": original_text,\n","            \"Translation A\": trans_a,\n","            \"Translation B\": trans_b,\n","            \"Chain-of-Thought & Decision\": chain_of_thought,\n","            \"Preference Score\": pref\n","        }\n","        with open(csv_out_path, \"a\", newline=\"\", encoding=\"utf-8\") as f_csv:\n","            writer = csv.DictWriter(f_csv, fieldnames=fieldnames)\n","            writer.writerow(row_dict)\n","\n","    # Compute summary\n","    num_1 = sum(1 for p in all_prefs if p == 1)\n","    num_2 = sum(1 for p in all_prefs if p == 2)\n","    total_valid = num_1 + num_2\n","\n","    with open(txt_out_path, \"w\", encoding=\"utf-8\") as f_txt:\n","        f_txt.write(f\"Number of times preference=1 (Translation A): {num_1}\\n\")\n","        f_txt.write(f\"Number of times preference=2 (Translation B): {num_2}\\n\")\n","        f_txt.write(f\"Total valid comparisons: {total_valid}\\n\")\n","\n","    print(f\"[DONE] {ds_name} - {dialect} => preference=1: {num_1}, preference=2: {num_2}\")\n","\n","def main():\n","    for dialect in DIALECTS:\n","        for ds_name in DATASET_PATHS.keys():\n","            process_dataset(dialect, ds_name)\n","\n","    print(\"All preference comparisons complete!\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26403,"status":"ok","timestamp":1737429508939,"user":{"displayName":"Jacob Cheung","userId":"11124663735002671005"},"user_tz":300},"id":"ciIE2_2Q3ct9","outputId":"c1110206-8d72-45d4-a185-a6bf9d11c9e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"URQ1tlvSMcOk"},"outputs":[],"source":["# Gemini 1.5 Pro\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install openai==0.28\n","\n","import os\n","import re\n","import csv\n","import pandas as pd\n","import openai\n","from tqdm import tqdm\n","\n","GEMINI_API_KEY = \"API-KEY\"\n","\n","DATASET_PATHS = {\n","    \"FOLIO(1000)\":               \"aligned_folio1000.csv\",\n","    \"BoolQ (1000)\":              \"GLUE + SuperGLUE/aligned_boolq_1000.csv\",\n","    \"COPA (500)\":                \"GLUE + SuperGLUE/aligned_copa_500.csv\",\n","    \"MultiRC (1000)\":            \"GLUE + SuperGLUE/aligned_multirc_1000.csv\",\n","    \"SST-2 (1000)\":              \"GLUE + SuperGLUE/aligned_sst-2_1000.csv\",\n","    \"WSC (659)\":                 \"GLUE + SuperGLUE/aligned_wsc_659.csv\",\n","    \"GSM8K(1000)\":               \"aligned_gsm8k1000.csv\",\n","    \"HumanEVAL(164)\":            \"aligned_humaneval164.csv\",\n","    \"Logic Bench MCQ(480)\":      \"aligned_logic_bench_mcq480.csv\",\n","    \"Logic Bench YN(500)\":       \"aligned_logic_bench_yn500.csv\",\n","    \"MBPP(374)\":                 \"aligned_mbpp374.csv\",\n","    \"SVAMP(700)\":                \"aligned_svamp700.csv\",\n","}\n","\n","DIALECTS = [\"AAVE\", \"ChcE\", \"CollSgE\", \"IndE\", \"JamE\"]\n","\n","BASE_INPUT_DIR = \"/content/drive/MyDrive/!!Multi-AAVENUE/Aligned Translations\"\n","BASE_OUTPUT_DIR = \"/content/drive/MyDrive/!!Multi-AAVENUE/Metrics/Preference Scores/Gemini 1.5\"\n","\n","COT_PROMPT = \"\"\"\n","You are an expert linguist with a strong command of {dialect}.\n","\n","You are given:\n","1) **Original Text (SAE)** – a standard American English version for reference.\n","2) **Translation A** – a version in the {dialect} dialect.\n","3) **Translation B** – another version in the {dialect} dialect.\n","\n","Your task: Decide which translation is better **in the context of the {dialect} dialect** with respect to:\n","- Fluency (grammar, syntax, word choice, overall naturalness in {dialect})\n","- Accuracy (faithfulness to the original meaning, but expressed naturally in {dialect})\n","- Readability (cohesion, clarity, and flow in {dialect})\n","- Cultural appropriateness (if relevant to {dialect})\n","\n","Provide a detailed chain-of-thought (reasoning) as to how you weigh these factors.\n","Then conclude with one final line in the exact format:\n","**\"Final preference score: X\"**\n","(where **X = 1** if you prefer Translation A, or **X = 2** if you prefer Translation B).\n","\n","Make sure you **reveal** your full thought process, then **end** with:\n","Final preference score: X\n","\"\"\"\n","\n","def get_preference_score(original_text: str, trans_a: str, trans_b: str, dialect: str):\n","    \"\"\"\n","    Returns: (model_full_response, preference_int)\n","       model_full_response: the entire chain-of-thought + final line\n","       preference_int: 1 or 2 if found, else -1\n","    \"\"\"\n","    try:\n","        # Prompt the user\n","        user_content = f\"\"\"Original Text (SAE):\n","{original_text}\n","\n","Translation A ({dialect}):\n","{trans_a}\n","\n","Translation B ({dialect}):\n","{trans_b}\n","\n","Please show your detailed reasoning focusing on {dialect} usage, then conclude with:\n","Final preference score: X\n","\"\"\"\n","\n","        response = openai.ChatCompletion.create(  \n","            model=\"gemini-1.5-pro\",  \n","            messages=[\n","                {\"role\": \"system\", \"content\": COT_PROMPT.format(dialect=dialect)},\n","                {\"role\": \"user\", \"content\": user_content}\n","            ],\n","            temperature=0.0,\n","            api_key=GEMINI_API_KEY  \n","        )\n","\n","        result_text = response[\"choices\"][0][\"message\"][\"content\"].strip()\n","\n","        # Parse final preference\n","        match = re.search(r\"Final preference score:\\s*([12])\", result_text)\n","        if match:\n","            pref = int(match.group(1))\n","        else:\n","            pref = -1\n","\n","        return (result_text, pref)\n","    except Exception as e:\n","        print(f\"Error retrieving preference: {e}\")\n","        return (\"\", -1)\n","\n","def process_dataset(dialect: str, ds_name: str):\n","    \"\"\"\n","    1) Build the input CSV path by combining the base path, the dialect, and the subpath from DATASET_PATHS[ds_name].\n","    2) Read the CSV -> columns: \"Original\", \"Filtered GPT 4o\" (Translation A), \"Filtered Multi-VALUE\" (Translation B).\n","    3) For each row, call get_preference_score(), capturing the entire chain-of-thought plus final line.\n","    4) Write results to CSV:\n","       [Original, Translation A, Translation B, Chain-of-Thought & Decision, Preference Score]\n","    5) Summarize how many times the model picked 1 vs 2 in a .txt file.\n","    \"\"\"\n","    # Subpath for this dataset\n","    if ds_name not in DATASET_PATHS:\n","        print(f\"[!] No path mapped for dataset: {ds_name}\")\n","        return\n","    subpath = DATASET_PATHS[ds_name]\n","\n","    input_path = os.path.join(BASE_INPUT_DIR, dialect, subpath)\n","\n","    if not os.path.isfile(input_path):\n","        print(f\"[!] File not found: {input_path} - skipping.\")\n","        return\n","\n","    df = pd.read_csv(input_path, encoding=\"utf-8\")\n","\n","    # Output folder\n","    out_folder = os.path.join(BASE_OUTPUT_DIR, dialect, ds_name)\n","    os.makedirs(out_folder, exist_ok=True)\n","\n","    csv_out_path = os.path.join(out_folder, f\"{ds_name}_preference.csv\")\n","    txt_out_path = os.path.join(out_folder, f\"{ds_name}_preference_summary.txt\")\n","\n","    all_prefs = []\n","\n","    fieldnames = [\n","        \"Original\",\n","        \"Translation A\",\n","        \"Translation B\",\n","        \"Chain-of-Thought & Decision\",\n","        \"Preference Score\"\n","    ]\n","    with open(csv_out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","        writer = csv.DictWriter(f, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"{ds_name} - {dialect}\"):\n","        original_text = str(row.get(\"Original\", \"\")).strip()\n","        trans_a = str(row.get(\"Filtered GPT 4o\", \"\")).strip()\n","        trans_b = str(row.get(\"Filtered Multi-VALUE\", \"\")).strip()\n","\n","        if not trans_a or not trans_b:\n","            chain_of_thought = \"(N/A: missing data)\"\n","            pref = -1\n","        else:\n","            chain_of_thought, pref = get_preference_score(\n","                original_text, trans_a, trans_b, dialect\n","            )\n","\n","        all_prefs.append(pref)\n","\n","        row_dict = {\n","            \"Original\": original_text,\n","            \"Translation A\": trans_a,\n","            \"Translation B\": trans_b,\n","            \"Chain-of-Thought & Decision\": chain_of_thought,\n","            \"Preference Score\": pref\n","        }\n","        with open(csv_out_path, \"a\", newline=\"\", encoding=\"utf-8\") as f_csv:\n","            writer = csv.DictWriter(f_csv, fieldnames=fieldnames)\n","            writer.writerow(row_dict)\n","\n","    num_1 = sum(1 for p in all_prefs if p == 1)\n","    num_2 = sum(1 for p in all_prefs if p == 2)\n","    total_valid = num_1 + num_2\n","\n","    with open(txt_out_path, \"w\", encoding=\"utf-8\") as f_txt:\n","        f_txt.write(f\"Number of times preference=1 (Translation A): {num_1}\\n\")\n","        f_txt.write(f\"Number of times preference=2 (Translation B): {num_2}\\n\")\n","        f_txt.write(f\"Total valid comparisons: {total_valid}\\n\")\n","\n","    print(f\"[DONE] {ds_name} - {dialect} => preference=1: {num_1}, preference=2: {num_2}\")\n","\n","def main():\n","    for dialect in DIALECTS:\n","        for ds_name in DATASET_PATHS.keys():\n","            process_dataset(dialect, ds_name)\n","\n","    print(\"All preference comparisons complete!\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":599},"executionInfo":{"elapsed":8422,"status":"error","timestamp":1737358525836,"user":{"displayName":"Jacob Cheung","userId":"11124663735002671005"},"user_tz":300},"id":"nJtr6BgbYKfY","outputId":"86fd65da-e6b2-4e4e-9326-7b4b453f5350"},"outputs":[],"source":["# Claude 3.5 Sonnet\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install anthropic\n","\n","import os\n","import re\n","import csv\n","import pandas as pd\n","import anthropic\n","from tqdm import tqdm\n","\n","anthropic_client = anthropic.Anthropic(api_key=\"API-KEY\")\n","\n","DATASET_PATHS = {\n","    \"FOLIO(1000)\":               \"aligned_folio1000.csv\",\n","    \"BoolQ (1000)\":              \"GLUE + SuperGLUE/aligned_boolq_1000.csv\",\n","    \"COPA (500)\":                \"GLUE + SuperGLUE/aligned_copa_500.csv\",\n","    \"MultiRC (1000)\":            \"GLUE + SuperGLUE/aligned_multirc_1000.csv\",\n","    \"SST-2 (1000)\":              \"GLUE + SuperGLUE/aligned_sst-2_1000.csv\",\n","    \"WSC (659)\":                 \"GLUE + SuperGLUE/aligned_wsc_659.csv\",\n","    \"GSM8K(1000)\":               \"aligned_gsm8k1000.csv\",\n","    \"HumanEVAL(164)\":            \"aligned_humaneval164.csv\",\n","    \"Logic Bench MCQ(480)\":      \"aligned_logic_bench_mcq480.csv\",\n","    \"Logic Bench YN(500)\":       \"aligned_logic_bench_yn500.csv\",\n","    \"MBPP(374)\":                 \"aligned_mbpp374.csv\",\n","    \"SVAMP(700)\":                \"aligned_svamp700.csv\",\n","}\n","\n","DIALECTS = [\"AAVE\", \"ChcE\", \"CollSgE\", \"IndE\", \"JamE\"]\n","\n","BASE_INPUT_DIR = \"/content/drive/MyDrive/!!Multi-AAVENUE/Aligned Translations\"\n","BASE_OUTPUT_DIR = \"/content/drive/MyDrive/!!Multi-AAVENUE/Metrics/Preference Scores/Claude 3.5 Sonnet\"\n","\n","COT_PROMPT = \"\"\"\n","You are an expert linguist with a strong command of {dialect}.\n","\n","You are given:\n","1) **Original Text (SAE)** – a standard American English version for reference.\n","2) **Translation A** – a version in the {dialect} dialect.\n","3) **Translation B** – another version in the {dialect} dialect.\n","\n","Your task: Decide which translation is better **in the context of the {dialect} dialect** with respect to:\n","- Fluency (grammar, syntax, word choice, overall naturalness in {dialect})\n","- Accuracy (faithfulness to the original meaning, but expressed naturally in {dialect})\n","- Readability (cohesion, clarity, and flow in {dialect})\n","- Cultural appropriateness (if relevant to {dialect})\n","\n","Provide a detailed chain-of-thought (reasoning) as to how you weigh these factors.\n","Then conclude with one final line in the exact format:\n","**\"Final preference score: X\"**\n","(where **X = 1** if you prefer Translation A, or **X = 2** if you prefer Translation B).\n","\n","Make sure you **reveal** your full thought process, then **end** with:\n","Final preference score: X\n","\"\"\"\n","\n","def get_preference_score(original_text: str, trans_a: str, trans_b: str, dialect: str):\n","    \"\"\"\n","    Returns: (model_full_response, preference_int)\n","       model_full_response: the entire chain-of-thought + final line\n","       preference_int: 1 or 2 if found, else -1\n","    \"\"\"\n","    try:\n","        # Prompt the user\n","        user_content = f\"\"\"Original Text (SAE):\n","{original_text}\n","\n","Translation A ({dialect}):\n","{trans_a}\n","\n","Translation B ({dialect}):\n","{trans_b}\n","\n","Please show your detailed reasoning focusing on {dialect} usage, then conclude with:\n","Final preference score: X\n","\"\"\"\n","\n","        # Call Anthropic API\n","        response = anthropic_client.messages.create(\n","            model=\"claude-3-5-sonnet-latest\",  \n","            system=COT_PROMPT.format(dialect=dialect),  \n","            messages=[\n","                {\"role\": \"user\", \"content\": user_content} \n","            ],\n","            max_tokens=1000,\n","            temperature=0.0\n","        )\n","\n","        result_text = response.content[0].text.strip()\n","\n","        match = re.search(r\"Final preference score:\\s*([12])\", result_text)\n","        if match:\n","            pref = int(match.group(1))\n","        else:\n","            pref = -1\n","\n","        return (result_text, pref)\n","    except Exception as e:\n","        print(f\"Error retrieving preference: {e}\")\n","        return (\"\", -1)\n","\n","def process_dataset(dialect: str, ds_name: str):\n","    \"\"\"\n","    1) Build the input CSV path by combining the base path, the dialect, and the subpath from DATASET_PATHS[ds_name].\n","    2) Read the CSV -> columns: \"Original\", \"Filtered GPT 4o\" (Translation A), \"Filtered Multi-VALUE\" (Translation B).\n","    3) For each row, call get_preference_score(), capturing the entire chain-of-thought plus final line.\n","    4) Write results to CSV:\n","       [Original, Translation A, Translation B, Chain-of-Thought & Decision, Preference Score]\n","    5) Summarize how many times the model picked 1 vs 2 in a .txt file.\n","    \"\"\"\n","    if ds_name not in DATASET_PATHS:\n","        print(f\"[!] No path mapped for dataset: {ds_name}\")\n","        return\n","    subpath = DATASET_PATHS[ds_name]\n","\n","    input_path = os.path.join(BASE_INPUT_DIR, dialect, subpath)\n","\n","    if not os.path.isfile(input_path):\n","        print(f\"[!] File not found: {input_path} - skipping.\")\n","        return\n","\n","    df = pd.read_csv(input_path, encoding=\"utf-8\")\n","\n","    # Output folder\n","    out_folder = os.path.join(BASE_OUTPUT_DIR, dialect, ds_name)\n","    os.makedirs(out_folder, exist_ok=True)\n","\n","    csv_out_path = os.path.join(out_folder, f\"{ds_name}_preference.csv\")\n","    txt_out_path = os.path.join(out_folder, f\"{ds_name}_preference_summary.txt\")\n","\n","    all_prefs = []\n","\n","    fieldnames = [\n","        \"Original\",\n","        \"Translation A\",\n","        \"Translation B\",\n","        \"Chain-of-Thought & Decision\",\n","        \"Preference Score\"\n","    ]\n","    with open(csv_out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","        writer = csv.DictWriter(f, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"{ds_name} - {dialect}\"):\n","        original_text = str(row.get(\"Original\", \"\")).strip()\n","        trans_a = str(row.get(\"Filtered GPT 4o\", \"\")).strip()\n","        trans_b = str(row.get(\"Filtered Multi-VALUE\", \"\")).strip()\n","\n","        if not trans_a or not trans_b:\n","            chain_of_thought = \"(N/A: missing data)\"\n","            pref = -1\n","        else:\n","            chain_of_thought, pref = get_preference_score(\n","                original_text, trans_a, trans_b, dialect\n","            )\n","\n","        all_prefs.append(pref)\n","\n","        row_dict = {\n","            \"Original\": original_text,\n","            \"Translation A\": trans_a,\n","            \"Translation B\": trans_b,\n","            \"Chain-of-Thought & Decision\": chain_of_thought,\n","            \"Preference Score\": pref\n","        }\n","        with open(csv_out_path, \"a\", newline=\"\", encoding=\"utf-8\") as f_csv:\n","            writer = csv.DictWriter(f_csv, fieldnames=fieldnames)\n","            writer.writerow(row_dict)\n","\n","    num_1 = sum(1 for p in all_prefs if p == 1)\n","    num_2 = sum(1 for p in all_prefs if p == 2)\n","    total_valid = num_1 + num_2\n","\n","    with open(txt_out_path, \"w\", encoding=\"utf-8\") as f_txt:\n","        f_txt.write(f\"Number of times preference=1 (Translation A): {num_1}\\n\")\n","        f_txt.write(f\"Number of times preference=2 (Translation B): {num_2}\\n\")\n","        f_txt.write(f\"Total valid comparisons: {total_valid}\\n\")\n","\n","    print(f\"[DONE] {ds_name} - {dialect} => preference=1: {num_1}, preference=2: {num_2}\")\n","\n","def main():\n","    for dialect in DIALECTS:\n","        for ds_name in DATASET_PATHS.keys():\n","            process_dataset(dialect, ds_name)\n","\n","    print(\"All preference comparisons complete!\")\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
