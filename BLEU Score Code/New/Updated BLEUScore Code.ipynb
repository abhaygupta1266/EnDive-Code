{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29740,"status":"ok","timestamp":1737429919120,"user":{"displayName":"Jacob Cheung","userId":"11124663735002671005"},"user_tz":300},"id":"kRzS13V6booY","outputId":"6ea65194-f10d-4820-d493-be88917f3c9f"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4087,"status":"ok","timestamp":1737429923192,"user":{"displayName":"Jacob Cheung","userId":"11124663735002671005"},"user_tz":300},"id":"LmuyajzWcNpc","outputId":"9c14c443-15c7-4aed-8ec1-2abb4bb7eb65"},"outputs":[],"source":["!pip install pandas tqdm sacrebleu\n","\n","import os\n","import pandas as pd\n","import json\n","from tqdm import tqdm\n","from sacrebleu.metrics import BLEU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53057,"status":"ok","timestamp":1737430373720,"user":{"displayName":"Jacob Cheung","userId":"11124663735002671005"},"user_tz":300},"id":"FTjNZ0-3e0M4","outputId":"95e42bbd-f064-4f71-ab8f-2d7e61297ae2"},"outputs":[],"source":["#GPT 4o\n","\n","DIALECTS = ['AAVE', 'IndE', 'JamE', 'CollSgE', 'ChcE']\n","DATASETS = [\n","    'WSC (659)', 'SST-2 (1000)', 'MultiRC (1000)', 'COPA (500)', 'BoolQ (1000)',\n","    'FOLIO(1000)', 'GSM8K(1000)', 'HumanEVAL(164)', 'MBPP(374)', 'SVAMP(700)',\n","    'Logic Bench MCQ(480)', 'Logic Bench YN(500)'\n","]\n","THRESHOLD = 0.7\n","\n","COLUMN_MAPPING = {\n","    'BoolQ (1000)': ('SAE Passage', 'SAE Passage'),\n","    'COPA (500)': ('Premise', 'Premise'),\n","    'MultiRC (1000)': ('Paragraph', 'Paragraph'),\n","    'SST-2 (1000)': ('Original Sentence', 'Original Sentence'),\n","    'WSC (659)': ('Original Paragraph', 'Original Paragraph'),\n","    'SVAMP(700)': ('Original', 'Original'),\n","    'MBPP(374)': ('Original', 'Original'),\n","    'HumanEVAL(164)': ('Prompt', 'Prompt'),\n","    'GSM8K(1000)': ('Original', 'Original'),\n","    'FOLIO(1000)': ('Premises', 'Premises')\n","}\n","\n","def create_output_directories(dialect):\n","    base_path = f'/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/{dialect}'\n","    os.makedirs(base_path, exist_ok=True)\n","    glue_path = f'{base_path}/GLUE + SuperGLUE'\n","    os.makedirs(glue_path, exist_ok=True)\n","    for dataset in DATASETS:\n","        if dataset in ['WSC (659)', 'SST-2 (1000)', 'MultiRC (1000)', 'COPA (500)', 'BoolQ (1000)']:\n","            os.makedirs(f'{glue_path}/{dataset}', exist_ok=True)\n","        else:\n","            os.makedirs(f'{base_path}/{dataset}', exist_ok=True)\n","    return base_path, glue_path\n","\n","def calculate_bleu_score(reference, candidate):\n","    try:\n","        bleu = BLEU(effective_order=True)\n","        return bleu.sentence_score(candidate, [reference]).score / 100\n","    except Exception as e:\n","        print(f\"Error calculating BLEU score: {str(e)}\")\n","        return 0.0\n","\n","def process_dataset(dialect, dataset, input_path, output_base_path):\n","    try:\n","        if 'Logic Bench' in dataset:\n","            return process_logicbench(input_path, dialect, dataset, output_base_path)\n","\n","        sae_col, dialect_col_suffix = COLUMN_MAPPING.get(dataset, (None, None))\n","        if sae_col is None:\n","            raise ValueError(f\"Column mapping not found for dataset: {dataset}\")\n","\n","        dialect_col = f'{dialect} ({sae_col})'\n","        bleu_col = f'BLEU Score {sae_col}'\n","\n","        if input_path.endswith('.csv'):\n","            df = pd.read_csv(input_path)\n","        elif input_path.endswith('.json'):\n","            with open(input_path, 'r', encoding='utf-8') as f:\n","                data = json.load(f)\n","            df = pd.DataFrame(data)\n","        else:\n","            raise ValueError(\"Unsupported file format\")\n","\n","        df[sae_col] = df[sae_col].fillna('').astype(str)\n","        df[dialect_col] = df[dialect_col].fillna('').astype(str)\n","\n","        # Calculate BLEU scores with progress bar\n","        tqdm.pandas(desc=f'Calculating BLEU scores for {dialect} - {dataset}')\n","        df[bleu_col] = df.progress_apply(\n","            lambda row: calculate_bleu_score(row[sae_col], row[dialect_col]),\n","            axis=1\n","        )\n","\n","        # Save full dataset with BLEU scores\n","        output_path = f'{output_base_path}/{dataset}'\n","        df.to_csv(f'{output_path}/{dataset}_bleu_scores.csv', index=False)\n","\n","        # Save filtered dataset\n","        filtered_df = df[df[bleu_col] < THRESHOLD]\n","        filtered_df.to_csv(f'{output_path}/{dataset}_filtered_bleu_scores.csv', index=False)\n","\n","        total_samples = len(df)\n","        below_threshold = len(filtered_df)\n","        percentage = (below_threshold / total_samples) * 100\n","\n","        with open(f'{output_path}/{dataset}_percentage.txt', 'w') as f:\n","            f.write(f'Total Samples: {total_samples}\\n')\n","            f.write(f'Samples Below Threshold (<0.7): {below_threshold}\\n')\n","            f.write(f'Percentage Below Threshold: {percentage:.2f}%')\n","\n","        return total_samples, below_threshold, percentage\n","\n","    except Exception as e:\n","        print(f'\\nError in process_dataset for {dialect} - {dataset}: {str(e)}')\n","        return 0, 0, 0\n","\n","def process_logicbench(input_path, dialect, dataset, output_base_path):\n","    with open(input_path, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    processed_data = []\n","    for logic_type, logic_data in data.items():\n","        for sample in logic_data['samples']:\n","            if 'MCQ' in dataset:\n","                processed_sample = {\n","                    'Context': sample['context'],\n","                    'Choice 1': sample['choices']['choice_1'],\n","                    'Choice 2': sample['choices']['choice_2'],\n","                    'Choice 3': sample['choices']['choice_3'],\n","                    'Choice 4': sample['choices']['choice_4'],\n","                    'Answer': sample['answer'],\n","                    f'{dialect} (context)': sample[f'{dialect} (context)'],\n","                    'BLEU Score Context': calculate_bleu_score(sample['context'], sample[f'{dialect} (context)'])\n","                }\n","            elif 'YN' in dataset:\n","                processed_sample = {\n","                    'Context': sample['context'],\n","                    f'{dialect} (context)': sample[f'{dialect} (context)'],\n","                    'BLEU Score Context': calculate_bleu_score(sample['context'], sample[f'{dialect} (context)'])\n","                }\n","                for i, qa_pair in enumerate(sample['qa_pairs'][:4], 1):\n","                    processed_sample[f'Question {i}'] = qa_pair['question']\n","                    processed_sample[f'Answer {i}'] = qa_pair['answer']\n","            processed_data.append(processed_sample)\n","\n","    output_path = f'{output_base_path}/{dataset}'\n","    with open(f'{output_path}/{dataset}_bleu_scores.json', 'w', encoding='utf-8') as f:\n","        json.dump(processed_data, f, ensure_ascii=False, indent=2)\n","\n","    filtered_data = [sample for sample in processed_data if sample['BLEU Score Context'] < THRESHOLD]\n","    with open(f'{output_path}/{dataset}_filtered_bleu_scores.json', 'w', encoding='utf-8') as f:\n","        json.dump(filtered_data, f, ensure_ascii=False, indent=2)\n","\n","    total_samples = len(processed_data)\n","    below_threshold = len(filtered_data)\n","    percentage = (below_threshold / total_samples) * 100\n","\n","    with open(f'{output_path}/{dataset}_percentage.txt', 'w') as f:\n","        f.write(f'Total Samples: {total_samples}\\n')\n","        f.write(f'Samples Below Threshold (<0.7): {below_threshold}\\n')\n","        f.write(f'Percentage Below Threshold: {percentage:.2f}%')\n","\n","    return total_samples, below_threshold, percentage\n","\n","def main():\n","    for dialect in tqdm(DIALECTS, desc='Processing dialects'):\n","        output_base_path, glue_path = create_output_directories(dialect)\n","\n","        for dataset in tqdm(DATASETS, desc=f'Processing datasets for {dialect}'):\n","            if dataset in ['WSC (659)', 'SST-2 (1000)', 'MultiRC (1000)', 'COPA (500)', 'BoolQ (1000)']:\n","                input_path = f'/content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/GPT 4o/{dialect}/Glue + SuperGlue/{dataset}_{dialect}.csv'\n","                output_path = glue_path\n","            else:\n","                input_path = f'/content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/GPT 4o/{dialect}/{dataset}_{dialect}.{\"json\" if \"Logic Bench\" in dataset else \"csv\"}'\n","                output_path = output_base_path\n","\n","            try:\n","                total, below, percentage = process_dataset(\n","                    dialect,\n","                    dataset,\n","                    input_path,\n","                    output_path\n","                )\n","                if total > 0:\n","                    print(f'\\nProcessed {dataset} for {dialect}:')\n","                    print(f'Total: {total}, Below threshold: {below}, Percentage: {percentage:.2f}%')\n","            except Exception as e:\n","                print(f'\\nError processing {dataset} for {dialect}: {str(e)}')\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"17DuGXTaKHx6"},"outputs":[],"source":["# Multi-VALUE\n","\n","DIALECTS = ['AAVE', 'IndE', 'JamE', 'CollSgE', 'ChcE']\n","DATASETS = [\n","    'FOLIO(1000)', 'SVAMP(700)', 'MBPP(374)', 'Logic Bench YN(500)',\n","    'Logic Bench MCQ(480)', 'HumanEVAL(164)', 'GSM8K(1000)',\n","    'BoolQ (1000)', 'COPA (500)', 'MultiRC (1000)', 'SST-2 (1000)', 'WSC (659)'\n","]\n","THRESHOLD = 0.7\n","\n","COLUMN_MAPPING = {\n","    'BoolQ (1000)': ('SAE Passage', 'SAE Passage'),\n","    'COPA (500)': ('Premise', 'Premise'),\n","    'MultiRC (1000)': ('Paragraph', 'Paragraph'),\n","    'SST-2 (1000)': ('Original Sentence', 'Original Sentence'),\n","    'WSC (659)': ('Original Paragraph', 'Original Paragraph'),\n","    'SVAMP(700)': ('Original', 'Original'),\n","    'MBPP(374)': ('Original', 'Original'),\n","    'HumanEVAL(164)': ('Prompt', 'Prompt'),\n","    'GSM8K(1000)': ('Original', 'Original'),\n","    'FOLIO(1000)': ('Premises', 'Premises')\n","}\n","\n","def create_output_directories(dialect):\n","    base_path = f'/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/Multi-VALUE/{dialect}'\n","    os.makedirs(base_path, exist_ok=True)\n","    glue_path = f'{base_path}/GLUE + SuperGLUE'\n","    os.makedirs(glue_path, exist_ok=True)\n","    for dataset in DATASETS:\n","        if dataset in ['BoolQ (1000)', 'COPA (500)', 'MultiRC (1000)', 'SST-2 (1000)', 'WSC (659)']:\n","            os.makedirs(f'{glue_path}/{dataset}', exist_ok=True)\n","        else:\n","            os.makedirs(f'{base_path}/{dataset}', exist_ok=True)\n","    return base_path, glue_path\n","\n","def calculate_bleu_score(reference, candidate):\n","    try:\n","        bleu = BLEU(effective_order=True)\n","        return bleu.sentence_score(candidate, [reference]).score / 100\n","    except Exception as e:\n","        print(f\"Error calculating BLEU score: {str(e)}\")\n","        return 0.0\n","\n","def process_dataset(dialect, dataset, input_path, output_base_path):\n","    try:\n","        if 'Logic Bench' in dataset:\n","            return process_logicbench(input_path, dialect, dataset, output_base_path)\n","\n","        sae_col, dialect_col_suffix = COLUMN_MAPPING.get(dataset, (None, None))\n","        if sae_col is None:\n","            raise ValueError(f\"Column mapping not found for dataset: {dataset}\")\n","\n","        dialect_col = f'{dialect} ({sae_col})'  # Removed 'MV' prefix\n","        bleu_col = f'BLEU Score {sae_col}'\n","\n","        # Read dataset (CSV or JSON)\n","        if input_path.endswith('.csv'):\n","            df = pd.read_csv(input_path)\n","        elif input_path.endswith('.json'):\n","            with open(input_path, 'r', encoding='utf-8') as f:\n","                data = json.load(f)\n","            df = pd.DataFrame(data)\n","        else:\n","            raise ValueError(\"Unsupported file format\")\n","\n","        df[sae_col] = df[sae_col].fillna('').astype(str)\n","        df[dialect_col] = df[dialect_col].fillna('').astype(str)\n","\n","        # Calculate BLEU scores with progress bar\n","        tqdm.pandas(desc=f'Calculating BLEU scores for {dialect} - {dataset}')\n","        df[bleu_col] = df.progress_apply(\n","            lambda row: calculate_bleu_score(row[sae_col], row[dialect_col]),\n","            axis=1\n","        )\n","\n","        # Save full dataset with BLEU scores\n","        output_path = f'{output_base_path}/{dataset}'\n","        df.to_csv(f'{output_path}/{dataset}_bleu_scores.csv', index=False)\n","\n","        # Save filtered dataset\n","        filtered_df = df[df[bleu_col] < THRESHOLD]\n","        filtered_df.to_csv(f'{output_path}/{dataset}_filtered_bleu_scores.csv', index=False)\n","\n","        total_samples = len(df)\n","        below_threshold = len(filtered_df)\n","        percentage = (below_threshold / total_samples) * 100\n","\n","        with open(f'{output_path}/{dataset}_percentage.txt', 'w') as f:\n","            f.write(f'Total Samples: {total_samples}\\n')\n","            f.write(f'Samples Below Threshold (<0.7): {below_threshold}\\n')\n","            f.write(f'Percentage Below Threshold: {percentage:.2f}%')\n","\n","        return total_samples, below_threshold, percentage\n","\n","    except Exception as e:\n","        print(f'\\nError in process_dataset for {dialect} - {dataset}: {str(e)}')\n","        return 0, 0, 0\n","\n","def process_logicbench(input_path, dialect, dataset, output_base_path):\n","    with open(input_path, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    rows = []\n","    for logic_type, logic_data in data.items():\n","        axiom = logic_data['axiom']\n","        for sample in logic_data['samples']:\n","            context = sample['context']\n","            dialect_context = sample[f'{dialect} (context)']  # Removed 'MV' prefix\n","\n","            bleu_score = calculate_bleu_score(context, dialect_context)\n","\n","            rows.append({\n","                'Logic Type': logic_type,\n","                'Axiom': axiom,\n","                'Context': context,\n","                f'{dialect} (context)': dialect_context,\n","                'BLEU Score Context': bleu_score\n","            })\n","\n","    df = pd.DataFrame(rows)\n","\n","    output_path = f'{output_base_path}/{dataset}'\n","    df.to_csv(f'{output_path}/{dataset}_bleu_scores.csv', index=False)\n","\n","    filtered_df = df[df['BLEU Score Context'] < THRESHOLD]\n","    filtered_df.to_csv(f'{output_path}/{dataset}_filtered_bleu_scores.csv', index=False)\n","\n","    total_samples = len(df)\n","    below_threshold = len(filtered_df)\n","    percentage = (below_threshold / total_samples) * 100\n","\n","    with open(f'{output_path}/{dataset}_percentage.txt', 'w') as f:\n","        f.write(f'Total Samples: {total_samples}\\n')\n","        f.write(f'Samples Below Threshold (<0.7): {below_threshold}\\n')\n","        f.write(f'Percentage Below Threshold: {percentage:.2f}%')\n","\n","    return total_samples, below_threshold, percentage\n","\n","def main():\n","    for dialect in tqdm(DIALECTS, desc='Processing dialects'):\n","        output_base_path, glue_path = create_output_directories(dialect)\n","\n","        for dataset in tqdm(DATASETS, desc=f'Processing datasets for {dialect}'):\n","            if dataset in ['BoolQ (1000)', 'COPA (500)', 'MultiRC (1000)', 'SST-2 (1000)', 'WSC (659)']:\n","                input_path = f'/content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/Multi-VALUE/{dialect}/GLUE + SuperGLUE/{dataset}_MV{dialect}.csv'\n","                output_path = glue_path\n","            else:\n","                input_path = f'/content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/Multi-VALUE/{dialect}/{dataset}_MV{dialect}.{\"json\" if \"Logic Bench\" in dataset else \"csv\"}'\n","                output_path = output_base_path\n","\n","            try:\n","                total, below, percentage = process_dataset(\n","                    dialect,\n","                    dataset,\n","                    input_path,\n","                    output_path\n","                )\n","                if total > 0:\n","                    print(f'\\nProcessed {dataset} for {dialect}:')\n","                    print(f'Total: {total}, Below threshold: {below}, Percentage: {percentage:.2f}%')\n","            except Exception as e:\n","                print(f'\\nError processing {dataset} for {dialect}: {str(e)}')\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":716,"status":"ok","timestamp":1736834662585,"user":{"displayName":"abhay gupta","userId":"06781579352555862769"},"user_tz":300},"id":"eQWmOUt8abfS","outputId":"8ee6248c-177a-4e48-f0be-0e2fa42e903b"},"outputs":[],"source":["#specifically for AAVE Logic Bench YN\n","import os\n","import json\n","from tqdm import tqdm\n","from sacrebleu.metrics import BLEU\n","import pandas as pd\n","\n","# Define constants\n","DIALECT = 'AAVE'\n","DATASET = 'Logic Bench YN(500)'\n","THRESHOLD = 0.7\n","INPUT_PATH = '/content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/Multi-VALUE/AAVE/Logic Bench YN(500)_MVAAVE.json'\n","OUTPUT_PATH = '/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/Multi-VALUE/AAVE/Logic Bench YN(500)/'\n","\n","os.makedirs(OUTPUT_PATH, exist_ok=True)\n","\n","def calculate_bleu_score(reference, candidate):\n","    try:\n","        bleu = BLEU(effective_order=True)\n","        score = bleu.sentence_score(candidate, [reference]).score / 100\n","        return score\n","    except Exception as e:\n","        print(f\"Error calculating BLEU score: {str(e)}\")\n","        return 0.0\n","\n","with open(INPUT_PATH, 'r', encoding='utf-8') as f:\n","    data = json.load(f)\n","\n","rows = []\n","\n","for logic_type, logic_data in data.items():\n","    axiom = logic_data.get('axiom', '')\n","    for sample in tqdm(logic_data.get('samples', []), desc=f'Processing samples for {logic_type}'):\n","        context = sample.get('context', '')\n","        dialect_context = sample.get(f'{DIALECT} (context)', '')\n","        bleu_score = calculate_bleu_score(context, dialect_context)\n","        rows.append({\n","            'Logic Type': logic_type,\n","            'Axiom': axiom,\n","            'Context': context,\n","            f'{DIALECT} (context)': dialect_context,\n","            'BLEU Score Context': bleu_score\n","        })\n","\n","df = pd.DataFrame(rows)\n","\n","df.to_csv(f'{OUTPUT_PATH}/{DATASET}_bleu_scores.csv', index=False)\n","\n","filtered_df = df[df['BLEU Score Context'] < THRESHOLD]\n","\n","filtered_df.to_csv(f'{OUTPUT_PATH}/{DATASET}_filtered_bleu_scores.csv', index=False)\n","\n","total_samples = len(df)\n","below_threshold = len(filtered_df)\n","percentage = (below_threshold / total_samples) * 100 if total_samples > 0 else 0.0\n","\n","with open(f'{OUTPUT_PATH}/{DATASET}_percentage.txt', 'w') as f:\n","    f.write(f'Total Samples: {total_samples}\\n')\n","    f.write(f'Samples Below Threshold (<0.7): {below_threshold}\\n')\n","    f.write(f'Percentage Below Threshold: {percentage:.2f}%\\n')\n","\n","print(f'Processed {DATASET} for {DIALECT}:')\n","print(f'Total Samples: {total_samples}')\n","print(f'Samples Below Threshold: {below_threshold}')\n","print(f'Percentage Below Threshold: {percentage:.2f}%')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
