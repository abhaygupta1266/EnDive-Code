{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":18770,"status":"ok","timestamp":1736385848611,"user":{"displayName":"abhay gupta","userId":"06781579352555862769"},"user_tz":300},"id":"4OXErBUcepRH","outputId":"84a15da5-4d43-4c0b-ebde-dea06a02d1e0"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18990,"status":"ok","timestamp":1736385867599,"user":{"displayName":"abhay gupta","userId":"06781579352555862769"},"user_tz":300},"id":"ujRpTnlYhXvC","outputId":"5db2700c-7098-409b-bfda-e8ee3f535a61"},"outputs":[],"source":["!pip install openai==0.28\n","!pip install pandas\n","!pip install tqdm\n","!pip install json5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCgl9rAjRn9p"},"outputs":[],"source":["import openai\n","import pandas as pd\n","import json\n","from tqdm import tqdm\n","\n","openai.api_key = \"API-KEY\"\n","\n","def create_prompt(text):\n","    few_shot_examples = (\n","        \"Here are examples of African American Vernacular English (AAVE):\\n\"\n","        \"1. I was bewildered, but I knew dat it was no gud asking his ass to explain.\\n\"\n","        \"2. Cochran pontificated windily for da camera.\\n\"\n","        \"3. I don’t want them to follow in my footsteps, as I ain’t go to no college, but I want them to go.\\n\"\n","        f\"\\nHere is the input text: {text}\\n\"\n","        \"Please rewrite the input text in African American Vernacular English (AAVE).\"\n","    )\n","    return few_shot_examples\n","\n","def translate_to_aave(text):\n","    try:\n","        response = openai.ChatCompletion.create(\n","            model=\"gpt-4o\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are a language model capable of translating text into African American Vernacular English (AAVE).\"},\n","                {\"role\": \"user\", \"content\": create_prompt(text)}\n","            ],\n","            max_tokens=500,\n","            temperature=0.7\n","        )\n","        return response['choices'][0]['message']['content'].strip()\n","    except Exception as e:\n","        print(f\"Error translating text: {e}\")\n","        return None\n","\n","def process_csv(file_path, column_to_translate):\n","    df = pd.read_csv(file_path)\n","    translated_column = []\n","    total_rows = len(df)\n","    for idx, text in enumerate(tqdm(df[column_to_translate], desc=f\"Translating {column_to_translate}\"), start=1):\n","        translated_text = translate_to_aave(text)\n","        translated_column.append(translated_text)\n","        print(f\"Processed row {idx}/{total_rows}\")\n","    df[f\"AAVE ({column_to_translate})\"] = translated_column\n","    output_path = f\"/content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/GPT 4o/AAVE/Glue + SuperGlue/{file_path.split('/')[-1].replace('.csv', '_AAVE.csv')}\"\n","    df.to_csv(output_path, index=False)\n","    print(f\"Translated file saved to: {output_path}\")\n","\n","def process_json(file_path, key_to_translate):\n","    with open(file_path, \"r\") as file:\n","        data = json.load(file)\n","    translated_data = []\n","    total_items = len(data[\"propositional_logic\"][\"samples\"])\n","\n","    for idx, item in enumerate(tqdm(data[\"propositional_logic\"][\"samples\"], desc=f\"Translating {key_to_translate}\"), start=1):\n","        item_copy = item.copy()\n","        item_copy[f\"AAVE ({key_to_translate})\"] = translate_to_aave(item[key_to_translate])\n","        translated_data.append(item_copy)\n","        print(f\"Processed row {idx}/{total_items}\")\n","\n","    data[\"propositional_logic\"][\"samples\"] = translated_data\n","    output_path = f\"/content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/GPT 4o/AAVE/{file_path.split('/')[-1].replace('.json', '_AAVE.json')}\"\n","    with open(output_path, \"w\") as file:\n","        json.dump(data, file, indent=4)\n","    print(f\"Translated file saved to: {output_path}\")\n","\n","file_translation_map = {\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/GLUE + SUPERGLUE Datasets/BoolQ (1000).csv\": \"SAE Passage\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/GLUE + SUPERGLUE Datasets/COPA (500).csv\": \"Premise\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/GLUE + SUPERGLUE Datasets/MultiRC (1000).csv\": \"Paragraph\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/GLUE + SUPERGLUE Datasets/SST-2 (1000).csv\": \"Original Sentence\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/GLUE + SUPERGLUE Datasets/WSC (659).csv\": \"Original Paragraph\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/FOLIO(1000).csv\": \"Premises\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/GSM8K(1000).csv\": \"Original\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/HumanEVAL(164).csv\": \"Prompt\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/Logic Bench MCQ(480).json\": \"context\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/vDatasets/Logic Bench YN(500).json\": \"context\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/MBPP(374).csv\": \"Original\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/SVAMP(700).csv\": \"Original\"\n","}\n","\n","for file_path, column_or_key in file_translation_map.items():\n","    if file_path.endswith(\".csv\"):\n","        process_csv(file_path, column_or_key)\n","    elif file_path.endswith(\".json\"):\n","        process_json(file_path, column_or_key)\n","\n","print(\"All translations completed and saved to /content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/GPT 4o/AAVE.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":980692,"status":"ok","timestamp":1736386848287,"user":{"displayName":"abhay gupta","userId":"06781579352555862769"},"user_tz":300},"id":"aKBiB6Rp815B","outputId":"1f75fc26-2ae2-4a24-fcd2-f13b936ad164"},"outputs":[],"source":["import openai\n","import pandas as pd\n","import json\n","from tqdm import tqdm\n","\n","openai.api_key = \"API-KEY\"\n","\n","def create_prompt(text):\n","    few_shot_examples = (\n","        \"Here are examples of African American Vernacular English (AAVE):\\n\"\n","        \"1. I was bewildered, but I knew dat it was no gud asking his ass to explain.\\n\"\n","        \"2. Cochran pontificated windily for da camera.\\n\"\n","        \"3. I don’t want them to follow in my footsteps, as I ain’t go to no college, but I want them to go.\\n\"\n","        f\"\\nHere is the input text: {text}\\n\"\n","        \"Please rewrite the input text in African American Vernacular English (AAVE).\"\n","    )\n","    return few_shot_examples\n","\n","def translate_to_aave(text):\n","    try:\n","        response = openai.ChatCompletion.create(\n","            model=\"gpt-4o\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are a language model capable of translating text into African American Vernacular English (AAVE).\"},\n","                {\"role\": \"user\", \"content\": create_prompt(text)}\n","            ],\n","            max_tokens=500,\n","            temperature=0.7\n","        )\n","        return response['choices'][0]['message']['content'].strip()\n","    except Exception as e:\n","        print(f\"Error translating text: {e}\")\n","        return None\n","\n","def process_csv(file_path, column_to_translate):\n","    df = pd.read_csv(file_path)\n","    translated_column = []\n","    total_rows = len(df)\n","    for idx, text in enumerate(tqdm(df[column_to_translate], desc=f\"Translating {column_to_translate}\"), start=1):\n","        translated_text = translate_to_aave(text)\n","        translated_column.append(translated_text)\n","        print(f\"Processed row {idx}/{total_rows}\")\n","    df[f\"AAVE ({column_to_translate})\"] = translated_column\n","    output_path = f\"/content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/GPT 4o/AAVE/{file_path.split('/')[-1].replace('.csv', '_AAVE.csv')}\"\n","    df.to_csv(output_path, index=False)\n","    print(f\"Translated file saved to: {output_path}\")\n","\n","def process_json(file_path, key_to_translate):\n","    with open(file_path, \"r\") as file:\n","        data = json.load(file)\n","    translated_data = []\n","    total_items = len(data[\"propositional_logic\"][\"samples\"])\n","\n","    for idx, item in enumerate(tqdm(data[\"propositional_logic\"][\"samples\"], desc=f\"Translating {key_to_translate}\"), start=1):\n","        item_copy = item.copy()\n","        item_copy[f\"AAVE ({key_to_translate})\"] = translate_to_aave(item[key_to_translate])\n","        translated_data.append(item_copy)\n","        print(f\"Processed row {idx}/{total_items}\")\n","\n","    data[\"propositional_logic\"][\"samples\"] = translated_data\n","    output_path = f\"/content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/GPT 4o/AAVE/{file_path.split('/')[-1].replace('.json', '_AAVE.json')}\"\n","    with open(output_path, \"w\") as file:\n","        json.dump(data, file, indent=4)\n","    print(f\"Translated file saved to: {output_path}\")\n","\n","file_translation_map = {\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/MBPP(374).csv\": \"Original\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/SVAMP(700).csv\": \"Original\"\n","}\n","\n","for file_path, column_or_key in file_translation_map.items():\n","    if file_path.endswith(\".csv\"):\n","        process_csv(file_path, column_or_key)\n","    elif file_path.endswith(\".json\"):\n","        process_json(file_path, column_or_key)\n","\n","print(\"All translations completed and saved to /content/drive/MyDrive/!!Multi-AAVENUE/GPT 4o + Multi-VALUE Translated Datasets/GPT 4o/AAVE.\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
