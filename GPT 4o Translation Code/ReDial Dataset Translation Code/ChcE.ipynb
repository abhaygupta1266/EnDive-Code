{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4OXErBUcepRH"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujRpTnlYhXvC"},"outputs":[],"source":["!pip install openai==0.28\n","!pip install pandas\n","!pip install tqdm\n","!pip install json5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":708368,"status":"ok","timestamp":1735521047021,"user":{"displayName":"Jacob Cheung","userId":"11124663735002671005"},"user_tz":300},"id":"t7QVJjzUhhmZ","outputId":"166174af-977e-455c-ed3e-6aef6266d4ac"},"outputs":[],"source":["import openai\n","import pandas as pd\n","import json\n","from tqdm import tqdm\n","\n","openai.api_key = \"API-KEY\"\n","\n","def create_prompt(text):\n","    few_shot_examples = (\n","        \"Here are examples of Chicano English (ChcE):\\n\"\n","        \"1. When people wanna fight me I'm like \\\"well okay, well then I'll fight you.\\\"\\n\"\n","        \"2. They were saying that they had a lot of problems at Garner because it was a lot of fights and stuff.\\n\"\n","        \"3. I ain't really thinking about getting with J. or any other guy\\n\"\n","        f\"\\nHere is the input text: {text}\\n\"\n","        \"Please rewrite the input text in Chicano English (ChcE).\"\n","    )\n","    return few_shot_examples\n","\n","def translate_to_chce(text):\n","    try:\n","        response = openai.ChatCompletion.create(\n","            model=\"gpt-4o\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are a language model capable of translating text into Chicano English (ChcE).\"},\n","                {\"role\": \"user\", \"content\": create_prompt(text)}\n","            ],\n","            max_tokens=500,\n","            temperature=0.7\n","        )\n","        return response['choices'][0]['message']['content'].strip()\n","    except Exception as e:\n","        print(f\"Error translating text: {e}\")\n","        return None\n","\n","def process_csv(file_path, column_to_translate):\n","    df = pd.read_csv(file_path)\n","    translated_column = []\n","    total_rows = len(df)\n","    for idx, text in enumerate(tqdm(df[column_to_translate], desc=f\"Translating {column_to_translate}\"), start=1):\n","        translated_text = translate_to_chce(text)\n","        translated_column.append(translated_text)\n","        print(f\"Processed row {idx}/{total_rows}\")\n","    df[f\"ChcE ({column_to_translate})\"] = translated_column\n","    output_path = f\"/content/drive/MyDrive/!!Multi-AAVENUE/Translated Datasets/{file_path.split('/')[-1].replace('.csv', '_ChcE.csv')}\"\n","    df.to_csv(output_path, index=False)\n","    print(f\"Translated file saved to: {output_path}\")\n","\n","def process_json(file_path, key_to_translate):\n","    with open(file_path, \"r\") as file:\n","        data = json.load(file)\n","    translated_data = []\n","    total_items = len(data[\"propositional_logic\"][\"samples\"])\n","\n","    for idx, item in enumerate(tqdm(data[\"propositional_logic\"][\"samples\"], desc=f\"Translating {key_to_translate}\"), start=1):\n","        item_copy = item.copy()\n","        item_copy[f\"ChcE ({key_to_translate})\"] = translate_to_chce(item[key_to_translate])\n","        translated_data.append(item_copy)\n","        print(f\"Processed row {idx}/{total_items}\")\n","\n","    data[\"propositional_logic\"][\"samples\"] = translated_data\n","    output_path = f\"/content/drive/MyDrive/!!Multi-AAVENUE/Translated Datasets/{file_path.split('/')[-1].replace('.json', '_ChcE.json')}\"\n","    with open(output_path, \"w\") as file:\n","        json.dump(data, file, indent=4)\n","    print(f\"Translated file saved to: {output_path}\")\n","\n","file_translation_map = {\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/FOLIO(1000).csv\": \"Premises\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/GSM8K(1000).csv\": \"Original\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/HumanEVAL(164).csv\": \"Prompt\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/Logic Bench MCQ(480).json\": \"context\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/Logic Bench YN(500).json\": \"context\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/MBPP(374).csv\": \"Original\",\n","    \"/content/drive/MyDrive/!!Multi-AAVENUE/Original Datasets/SVAMP(700).csv\": \"Original\"\n","}\n","\n","for file_path, column_or_key in file_translation_map.items():\n","    if file_path.endswith(\".csv\"):\n","        process_csv(file_path, column_or_key)\n","    elif file_path.endswith(\".json\"):\n","        process_json(file_path, column_or_key)\n","\n","print(\"All translations completed and saved to /content/drive/MyDrive/!!Multi-AAVENUE/Translated Datasets.\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
