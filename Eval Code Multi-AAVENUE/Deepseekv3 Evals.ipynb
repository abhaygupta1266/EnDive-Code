{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y9q_F48kiVbO"
      },
      "outputs": [],
      "source": [
        "## NON-COT EVALS\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install openai pandas numpy regex tqdm\n",
        "\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import time\n",
        "import signal\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
        "\n",
        "DEEPSEEK_API_KEY = \"API-KEY\"\n",
        "client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=\"https://api.deepseek.com/\")\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "input_base_dir = \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o\"\n",
        "output_base_dir = \"/content/drive/MyDrive/!!Multi-AAVENUE/Evaluation Results\"\n",
        "dialects = [\"IndE\", \"AAVE\", \"JamE\", \"ChcE\", \"CollSgE\"]\n",
        "\n",
        "datasets = {\n",
        "    \"SVAMP\": \"SVAMP(700)/SVAMP(700)_filtered_bleu_scores.csv\",\n",
        "    \"MBPP\": \"MBPP(374)/MBPP(374)_filtered_bleu_scores.csv\",\n",
        "    \"LogicBenchYN\": \"Logic Bench YN(500)/Logic Bench YN(500)_filtered_bleu_scores.json\",\n",
        "    \"LogicBenchMCQ\": \"Logic Bench MCQ(480)/Logic Bench MCQ(480)_filtered_bleu_scores.json\",\n",
        "    \"HumanEVAL\": \"HumanEVAL(164)/HumanEVAL(164)_filtered_bleu_scores.csv\",\n",
        "    \"GSM8K\": \"GSM8K(1000)/GSM8K(1000)_filtered_bleu_scores.csv\",\n",
        "    \"FOLIO\": \"FOLIO(1000)/FOLIO(1000)_filtered_bleu_scores.csv\",\n",
        "    \"WSC\": \"GLUE + SuperGLUE/WSC (659)/WSC (659)_filtered_bleu_scores.csv\",\n",
        "    \"SST-2\": \"GLUE + SuperGLUE/SST-2 (1000)/SST-2 (1000)_filtered_bleu_scores.csv\",\n",
        "    \"MultiRC\": \"GLUE + SuperGLUE/MultiRC (1000)/MultiRC (1000)_filtered_bleu_scores.csv\",\n",
        "    \"COPA\": \"GLUE + SuperGLUE/COPA (500)/COPA (500)_filtered_bleu_scores.csv\",\n",
        "    \"BoolQ\": \"GLUE + SuperGLUE/BoolQ (1000)/BoolQ (1000)_filtered_bleu_scores.csv\"\n",
        "}\n",
        "\n",
        "models = [\"deepseek-chat\"]\n",
        "\n",
        "def write_row_to_csv(row: dict, filename: str):\n",
        "    mode = 'a'\n",
        "    with open(filename, mode, newline='', encoding=\"utf-8\") as csvfile:\n",
        "        df = pd.DataFrame([row])\n",
        "        write_header = csvfile.tell() == 0\n",
        "        df.to_csv(csvfile, index=False, header=write_header)\n",
        "        csvfile.flush()\n",
        "\n",
        "def prompt_deepseek_model_with_timeout(model_name: str, system_message: str, user_message: str, timeout: int = 25, retries=5, backoff_factor=2) -> str:\n",
        "    def prompt():\n",
        "        return client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                {\"role\": \"user\", \"content\": user_message}\n",
        "            ],\n",
        "            temperature=TEMPERATURE,\n",
        "            max_tokens=4096\n",
        "        ).choices[0].message.content\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        with ThreadPoolExecutor(max_workers=1) as executor:\n",
        "            future = executor.submit(prompt)\n",
        "            try:\n",
        "                response = future.result(timeout=timeout)\n",
        "                return response\n",
        "            except TimeoutError:\n",
        "                print(f\"Timeout: Skipping this row after {timeout} seconds.\")\n",
        "                return None\n",
        "            except Exception as e:\n",
        "                wait_time = backoff_factor ** attempt\n",
        "                print(f\"API error: {e}. Retrying in {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "    print(\"Maximum retries exceeded. Skipping this row.\")\n",
        "    return None\n",
        "\n",
        "def clean_code(generated_code: str) -> str:\n",
        "    cleaned_code = re.sub(r\"```(?:python)?\", \"\", generated_code, flags=re.DOTALL)\n",
        "    cleaned_code = re.sub(r\"```\", \"\", cleaned_code, flags=re.DOTALL)\n",
        "    return cleaned_code.strip()\n",
        "\n",
        "def extract_response(response: str, pattern: str) -> str:\n",
        "    if not response:\n",
        "        return \"\"\n",
        "    match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)\n",
        "    return match.group(1).strip() if match else \"\"\n",
        "\n",
        "def evaluate_response(model_answer: str, expected_answer: str) -> bool:\n",
        "    return model_answer.strip().lower() == expected_answer.strip().lower()\n",
        "\n",
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "def alarm_handler(signum, frame):\n",
        "    raise TimeoutException(\"Execution timed out!\")\n",
        "\n",
        "def run_test_cases(generated_code: str, test_cases: str, timeout=5) -> (bool, str):\n",
        "    exec_globals = {}\n",
        "    try:\n",
        "        signal.signal(signal.SIGALRM, alarm_handler)\n",
        "        signal.alarm(timeout)\n",
        "        exec(generated_code, exec_globals)\n",
        "        exec(test_cases, exec_globals)\n",
        "        signal.alarm(0)\n",
        "        return True, \"\"\n",
        "    except TimeoutException as e:\n",
        "        signal.alarm(0)\n",
        "        return False, str(e)\n",
        "    except AssertionError as e:\n",
        "        signal.alarm(0)\n",
        "        return False, f\"AssertionError: {str(e)}\"\n",
        "    except SyntaxError as e:\n",
        "        signal.alarm(0)\n",
        "        return False, f\"SyntaxError: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        signal.alarm(0)\n",
        "        return False, f\"RuntimeError: {str(e)}\"\n",
        "\n",
        "def parse_gt_to_int(gt: str) -> str:\n",
        "    match = re.search(r\"choice_(\\d+)\", gt, re.IGNORECASE)\n",
        "    if match: return match.group(1)\n",
        "    match2 = re.search(r\"\\d+\", gt)\n",
        "    if match2: return match2.group(0)\n",
        "    return \"\"\n",
        "\n",
        "def extract_integer_from_response(response_text: str) -> str:\n",
        "    match = re.search(r\"Answer:\\s*(\\d+)\", response_text)\n",
        "    return match.group(1).strip() if match else \"\"\n",
        "\n",
        "def check_mcq_correctness(model_digit: str, gt_digit: str) -> bool:\n",
        "    return (model_digit == gt_digit) and bool(model_digit)\n",
        "\n",
        "model_output_mapping = {\n",
        "    \"deepseek-chat\": os.path.join(output_base_dir, \"DeepSeek-V3_NonCoT\")\n",
        "}\n",
        "\n",
        "def process_dataset(model_name: str, dataset_name: str, file_path: str, dialect: str):\n",
        "    try:\n",
        "        if dataset_name in [\"LogicBenchYN\", \"LogicBenchMCQ\"]:\n",
        "            with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "        else:\n",
        "            data = pd.read_csv(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load dataset {dataset_name} for dialect {dialect}: {e}\")\n",
        "        return\n",
        "\n",
        "    if dataset_name not in [\"LogicBenchYN\", \"LogicBenchMCQ\"]:\n",
        "        data = data.drop(columns=[col for col in data.columns if \"BLEU Score\" in col], errors=\"ignore\")\n",
        "\n",
        "    if model_name in model_output_mapping:\n",
        "        model_output_dir = os.path.join(model_output_mapping[model_name], dialect, dataset_name)\n",
        "    else:\n",
        "        model_output_dir = os.path.join(output_base_dir, model_name.replace(\"-\", \"\"), dialect, dataset_name)\n",
        "    os.makedirs(model_output_dir, exist_ok=True)\n",
        "    csv_file = os.path.join(model_output_dir, f\"{dataset_name}_results.csv\")\n",
        "\n",
        "    correct_count = 0\n",
        "    total = 0\n",
        "\n",
        "    if isinstance(data, pd.DataFrame):\n",
        "        total_rows = len(data)\n",
        "    else:\n",
        "        total_rows = len(data)\n",
        "\n",
        "    # NON-COT Prompts\n",
        "\n",
        "    if dataset_name == \"SVAMP\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                problem = row[f\"{dialect} (Original)\"]\n",
        "                question = row[\"Question\"]\n",
        "                expected = str(row[\"Answer\"])\n",
        "                user_prompt = (\n",
        "                    \"Given a mathematics problem, determine the answer.\\n\"\n",
        "                    f\"Context: {problem}\\nQuestion: {question}\\n\"\n",
        "                    \"Final Numeric Answer:\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Final Numeric Answer:\\s*(.+)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Original)\": problem,\n",
        "                    \"Question\": question,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"MBPP\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows,\n",
        "                    desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                problem = row[f\"{dialect} (Original)\"]\n",
        "                test_cases = row[\"Test_Cases\"]\n",
        "                user_prompt = (\n",
        "                    \"Given a coding problem, produce a Python function that solves it.\\n\"\n",
        "                    \"Output the code starting with 'Answer:' on its own line.\\n\"\n",
        "                    f\"Problem: {problem}\\nTest Cases: {test_cases}\\nAnswer:\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                generated_code = clean_code(response)\n",
        "                pattern = r\"Answer:\\s*(.+)\"\n",
        "                code = extract_response(generated_code, pattern)\n",
        "                if not code:\n",
        "                    continue\n",
        "                is_correct, error_msg = run_test_cases(code, test_cases, timeout=5)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Original)\": problem,\n",
        "                    \"Code\": code,\n",
        "                    \"Correct\": int(is_correct),\n",
        "                    \"Error Message\": error_msg\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"LogicBenchYN\":\n",
        "        pbar = tqdm(data, total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"task\")\n",
        "        for task in pbar:\n",
        "            try:\n",
        "                context = task[f\"{dialect} (context)\"]\n",
        "                for i in range(1, 5):\n",
        "                    question_key = f\"Question {i}\"\n",
        "                    answer_key = f\"Answer {i}\"\n",
        "                    question = task.get(question_key, \"\")\n",
        "                    expected = task.get(answer_key, \"\")\n",
        "                    if not question or not expected:\n",
        "                        continue\n",
        "                    user_prompt = (\n",
        "                        \"Given the context below, answer yes or no.\\n\"\n",
        "                        f\"Context: {context}\\nQuestion: {question}\\n\"\n",
        "                        \"Final Answer (yes/no):\"\n",
        "                    )\n",
        "                    system_prompt = \"You are a helpful assistant.\"\n",
        "                    response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                    if response is None:\n",
        "                        continue\n",
        "                    pattern = r\"(yes|no)\"\n",
        "                    model_answer = extract_response(response, pattern)\n",
        "                    is_correct = evaluate_response(model_answer, expected)\n",
        "                    total += 1\n",
        "                    if is_correct:\n",
        "                        correct_count += 1\n",
        "                    row_dict = {\n",
        "                        f\"{dialect} (Context)\": context,\n",
        "                        \"Question\": question,\n",
        "                        \"Expected Answer\": expected,\n",
        "                        \"Model Answer\": model_answer,\n",
        "                        \"Correct\": is_correct\n",
        "                    }\n",
        "                    write_row_to_csv(row_dict, csv_file)\n",
        "                    if total % 2 == 0:\n",
        "                        acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                        pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing task: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"LogicBenchMCQ\":\n",
        "        pbar = tqdm(data, total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"task\")\n",
        "        for task in pbar:\n",
        "            try:\n",
        "                context = task[f\"{dialect} (context)\"]\n",
        "                choices = [task.get(f\"Choice {i+1}\", \"\") for i in range(4)]\n",
        "                ground_truth_raw = task.get(\"Answer\", \"\")\n",
        "                gt_digit = parse_gt_to_int(ground_truth_raw)\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                user_prompt = (\n",
        "                    f\"Context:\\n{context}\\n\\n\"\n",
        "                    \"Choices:\\n\"\n",
        "                    f\"1) {choices[0]}\\n\"\n",
        "                    f\"2) {choices[1]}\\n\"\n",
        "                    f\"3) {choices[2]}\\n\"\n",
        "                    f\"4) {choices[3]}\\n\"\n",
        "                    \"Final Answer (1,2,3,4):\"\n",
        "                )\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                predicted_digit = extract_integer_from_response(response)\n",
        "                was_correct = check_mcq_correctness(predicted_digit, gt_digit)\n",
        "                total += 1\n",
        "                if was_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Context)\": context,\n",
        "                    \"Choice 1\": choices[0],\n",
        "                    \"Choice 2\": choices[1],\n",
        "                    \"Choice 3\": choices[2],\n",
        "                    \"Choice 4\": choices[3],\n",
        "                    \"Expected Answer\": ground_truth_raw,\n",
        "                    \"Model Answer\": response,\n",
        "                    \"Correct\": was_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing MCQ: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"HumanEVAL\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                prompt_text = row[f\"{dialect} (Prompt)\"]\n",
        "                test_cases = row[\"Test_Cases\"]\n",
        "                user_prompt = (\n",
        "                    \"Given a coding problem, produce Python code.\\n\"\n",
        "                    \"Start with 'Answer:' on its own line.\\n\"\n",
        "                    f\"Problem: {prompt_text}\\nTest Cases: {test_cases}\\nAnswer:\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                generated_code = clean_code(response)\n",
        "                pattern = r\"Answer:\\s*(.+)\"\n",
        "                code = extract_response(generated_code, pattern)\n",
        "                if not code:\n",
        "                    continue\n",
        "                is_correct, error_msg = run_test_cases(code, test_cases)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Prompt)\": prompt_text,\n",
        "                    \"Code\": code,\n",
        "                    \"Correct\": int(is_correct),\n",
        "                    \"Error Message\": error_msg\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"GSM8K\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                problem = row[f\"{dialect} (Original)\"]\n",
        "                expected = str(row[\"Answer\"])\n",
        "                user_prompt = (\n",
        "                    \"Given the math problem:\\n\"\n",
        "                    f\"{problem}\\n\"\n",
        "                    \"Provide a single numeric answer.\\n\"\n",
        "                    \"Answer:\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*([0-9.\\-]+)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                if not model_answer:\n",
        "                    pattern_alt = r\"Answer:\\s*([0-9.\\-]+)\"\n",
        "                    match = re.search(pattern_alt, response, re.IGNORECASE)\n",
        "                    if match:\n",
        "                        model_answer = match.group(1)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Original)\": problem,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"FOLIO\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                premises = row[f\"{dialect} (Premises)\"]\n",
        "                conclusion = row[\"Conclusion\"]\n",
        "                expected = row[\"Label\"]\n",
        "                user_prompt = (\n",
        "                    f\"Determine if the conclusion is True, False, or Uncertain.\\n\"\n",
        "                    f\"Premises: {premises}\\nConclusion: {conclusion}\\n\"\n",
        "                    \"Answer:\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(True|False|Uncertain)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Premises)\": premises,\n",
        "                    \"Conclusion\": conclusion,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"WSC\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                paragraph = row[f\"{dialect} (Original Paragraph)\"]\n",
        "                span1 = row[\"Span 1\"]\n",
        "                span2 = row[\"Span 2\"]\n",
        "                expected = str(row[\"Actual Label\"])\n",
        "                user_prompt = (\n",
        "                    f\"Determine if Span 2 refers to Span 1.\\n\"\n",
        "                    f\"Paragraph: {paragraph}\\nSpan 1: {span1}\\nSpan 2: {span2}\\n\"\n",
        "                    \"Answer (1 for same, 0 for not):\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(\\d)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Original Paragraph)\": paragraph,\n",
        "                    \"Span 1\": span1,\n",
        "                    \"Span 2\": span2,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"SST-2\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                sentence = row[f\"{dialect} (Original Sentence)\"]\n",
        "                expected = str(row[\"Actual Label\"])\n",
        "                user_prompt = (\n",
        "                    f\"Given the sentence: \\\"{sentence}\\\", is it positive (1) or negative (0)?\\n\"\n",
        "                    \"Answer:\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(\\d)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Original Sentence)\": sentence,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"MultiRC\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                paragraph = row[f\"{dialect} (Paragraph)\"]\n",
        "                question = row[\"Question\"]\n",
        "                answer_choice = row[\"Answer Choice\"]\n",
        "                expected = str(row[\"Actual Label\"])\n",
        "                user_prompt = (\n",
        "                    f\"Paragraph: {paragraph}\\n\"\n",
        "                    f\"Question: {question}\\n\"\n",
        "                    f\"Answer Choice: {answer_choice}\\n\"\n",
        "                    \"Is it correct (1) or incorrect (0)?\\nAnswer:\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(\\d)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Paragraph)\": paragraph,\n",
        "                    \"Question\": question,\n",
        "                    \"Answer Choice\": answer_choice,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"COPA\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                premise = row[f\"{dialect} (Premise)\"]\n",
        "                choice1 = row[\"Choice 1\"]\n",
        "                choice2 = row[\"Choice 2\"]\n",
        "                expected = str(row[\"Actual Answer\"])\n",
        "                user_prompt = (\n",
        "                    f\"Given the premise and two choices:\\nPremise: {premise}\\n\"\n",
        "                    f\"Choice 1: {choice1}\\nChoice 2: {choice2}\\n\"\n",
        "                    \"Which is more plausible, 0 or 1?\\nAnswer:\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(\\d)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Premise)\": premise,\n",
        "                    \"Choice 1\": choice1,\n",
        "                    \"Choice 2\": choice2,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"BoolQ\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                passage = row[f\"{dialect} (SAE Passage)\"]\n",
        "                question = row[\"SAE Question\"]\n",
        "                expected = str(row[\"Actual Label\"])\n",
        "                user_prompt = (\n",
        "                    f\"Passage: \\\"{passage}\\\"\\n\"\n",
        "                    f\"Question: \\\"{question}\\\"\\n\"\n",
        "                    \"Is the answer TRUE or FALSE?\\nAnswer:\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(TRUE|FALSE)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                if not model_answer:\n",
        "                    pattern_alt = r\"Answer:\\s*(TRUE|FALSE)\"\n",
        "                    match = re.search(pattern_alt, str(response), re.IGNORECASE)\n",
        "                    if match:\n",
        "                        model_answer = match.group(1).upper()\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (SAE Passage)\": passage,\n",
        "                    \"SAE Question\": question,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    else:\n",
        "        print(f\"Dataset {dataset_name} not recognized for processing.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        accuracy = (correct_count / total * 100) if total > 0 else 0\n",
        "        with open(os.path.join(model_output_dir, f\"{dataset_name}_accuracy.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"Total instances: {total}\\n\")\n",
        "            f.write(f\"Correct answers: {correct_count}\\n\")\n",
        "            f.write(f\"Accuracy: {accuracy:.2f}%\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing accuracy file for dataset {dataset_name}: {e}\")\n",
        "\n",
        "for model in models:\n",
        "    for dialect in dialects:\n",
        "        for dataset_name, rel_path in datasets.items():\n",
        "            full_path = os.path.join(input_base_dir, dialect, rel_path)\n",
        "            if os.path.exists(full_path):\n",
        "                process_dataset(model, dataset_name, full_path, dialect)\n",
        "            else:\n",
        "                print(f\"File not found: {full_path}\")\n",
        "\n",
        "print(\"Non-CoT evaluation complete! Results have been saved.\")\n",
        "try:\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()\n",
        "except ImportError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## COT EVALS\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install openai pandas numpy regex tqdm\n",
        "\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import time\n",
        "import signal\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
        "\n",
        "DEEPSEEK_API_KEY = \"API-KEY\"\n",
        "client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=\"https://api.deepseek.com/\")\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "input_base_dir = \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o\"\n",
        "output_base_dir = \"/content/drive/MyDrive/!!Multi-AAVENUE/Evaluation Results\"\n",
        "dialects = [\"IndE\", \"AAVE\", \"JamE\", \"ChcE\", \"CollSgE\"]\n",
        "\n",
        "datasets = {\n",
        "    \"SVAMP\": \"SVAMP(700)/SVAMP(700)_filtered_bleu_scores.csv\",\n",
        "    \"MBPP\": \"MBPP(374)/MBPP(374)_filtered_bleu_scores.csv\",\n",
        "    \"LogicBenchYN\": \"Logic Bench YN(500)/Logic Bench YN(500)_filtered_bleu_scores.json\",\n",
        "    \"LogicBenchMCQ\": \"Logic Bench MCQ(480)/Logic Bench MCQ(480)_filtered_bleu_scores.json\",\n",
        "    \"HumanEVAL\": \"HumanEVAL(164)/HumanEVAL(164)_filtered_bleu_scores.csv\",\n",
        "    \"GSM8K\": \"GSM8K(1000)/GSM8K(1000)_filtered_bleu_scores.csv\",\n",
        "    \"FOLIO\": \"FOLIO(1000)/FOLIO(1000)_filtered_bleu_scores.csv\",\n",
        "    \"WSC\": \"GLUE + SuperGLUE/WSC (659)/WSC (659)_filtered_bleu_scores.csv\",\n",
        "    \"SST-2\": \"GLUE + SuperGLUE/SST-2 (1000)/SST-2 (1000)_filtered_bleu_scores.csv\",\n",
        "    \"MultiRC\": \"GLUE + SuperGLUE/MultiRC (1000)/MultiRC (1000)_filtered_bleu_scores.csv\",\n",
        "    \"COPA\": \"GLUE + SuperGLUE/COPA (500)/COPA (500)_filtered_bleu_scores.csv\",\n",
        "    \"BoolQ\": \"GLUE + SuperGLUE/BoolQ (1000)/BoolQ (1000)_filtered_bleu_scores.csv\"\n",
        "}\n",
        "\n",
        "models = [\"deepseek-chat\"]\n",
        "\n",
        "def write_row_to_csv(row: dict, filename: str):\n",
        "    mode = 'a'\n",
        "    with open(filename, mode, newline='', encoding=\"utf-8\") as csvfile:\n",
        "        df = pd.DataFrame([row])\n",
        "        write_header = csvfile.tell() == 0\n",
        "        df.to_csv(csvfile, index=False, header=write_header)\n",
        "        csvfile.flush()\n",
        "\n",
        "def prompt_deepseek_model_with_timeout(model_name: str, system_message: str, user_message: str, timeout: int = 25, retries=5, backoff_factor=2) -> str:\n",
        "    def prompt():\n",
        "        return client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                {\"role\": \"user\", \"content\": user_message}\n",
        "            ],\n",
        "            temperature=TEMPERATURE,\n",
        "            max_tokens=4096\n",
        "        ).choices[0].message.content\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        with ThreadPoolExecutor(max_workers=1) as executor:\n",
        "            future = executor.submit(prompt)\n",
        "            try:\n",
        "                response = future.result(timeout=timeout)\n",
        "                return response\n",
        "            except TimeoutError:\n",
        "                print(f\"Timeout: Skipping this row after {timeout} seconds.\")\n",
        "                return None\n",
        "            except Exception as e:\n",
        "                wait_time = backoff_factor ** attempt\n",
        "                print(f\"API error: {e}. Retrying in {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "    print(\"Maximum retries exceeded. Skipping this row.\")\n",
        "    return None\n",
        "\n",
        "def clean_code(generated_code: str) -> str:\n",
        "    cleaned_code = re.sub(r\"```(?:python)?\", \"\", generated_code, flags=re.DOTALL)\n",
        "    cleaned_code = re.sub(r\"```\", \"\", cleaned_code, flags=re.DOTALL)\n",
        "    return cleaned_code.strip()\n",
        "\n",
        "def extract_response(response: str, pattern: str) -> str:\n",
        "    if not response:\n",
        "        return \"\"\n",
        "    match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)\n",
        "    return match.group(1).strip() if match else \"\"\n",
        "\n",
        "def evaluate_response(model_answer: str, expected_answer: str) -> bool:\n",
        "    return model_answer.strip().lower() == expected_answer.strip().lower()\n",
        "\n",
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "def alarm_handler(signum, frame):\n",
        "    raise TimeoutException(\"Execution timed out!\")\n",
        "\n",
        "def run_test_cases(generated_code: str, test_cases: str, timeout=5) -> (bool, str):\n",
        "    exec_globals = {}\n",
        "    try:\n",
        "        signal.signal(signal.SIGALRM, alarm_handler)\n",
        "        signal.alarm(timeout)\n",
        "        exec(generated_code, exec_globals)\n",
        "        exec(test_cases, exec_globals)\n",
        "        signal.alarm(0)\n",
        "        return True, \"\"\n",
        "    except TimeoutException as e:\n",
        "        signal.alarm(0)\n",
        "        return False, str(e)\n",
        "    except AssertionError as e:\n",
        "        signal.alarm(0)\n",
        "        return False, f\"AssertionError: {str(e)}\"\n",
        "    except SyntaxError as e:\n",
        "        signal.alarm(0)\n",
        "        return False, f\"SyntaxError: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        signal.alarm(0)\n",
        "        return False, f\"RuntimeError: {str(e)}\"\n",
        "\n",
        "def parse_gt_to_int(gt: str) -> str:\n",
        "    match = re.search(r\"choice_(\\d+)\", gt, re.IGNORECASE)\n",
        "    if match: return match.group(1)\n",
        "    match2 = re.search(r\"\\d+\", gt)\n",
        "    if match2: return match2.group(0)\n",
        "    return \"\"\n",
        "\n",
        "def extract_integer_from_response(response_text: str) -> str:\n",
        "    match = re.search(r\"Answer:\\s*(\\d+)\", response_text)\n",
        "    return match.group(1).strip() if match else \"\"\n",
        "\n",
        "def check_mcq_correctness(model_digit: str, gt_digit: str) -> bool:\n",
        "    return (model_digit == gt_digit) and bool(model_digit)\n",
        "\n",
        "model_output_mapping = {\n",
        "    \"deepseek-chat\": os.path.join(output_base_dir, \"DeepSeek-V3_CoT\")\n",
        "}\n",
        "\n",
        "def process_dataset(model_name: str, dataset_name: str, file_path: str, dialect: str):\n",
        "    try:\n",
        "        if dataset_name in [\"LogicBenchYN\", \"LogicBenchMCQ\"]:\n",
        "            with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "        else:\n",
        "            data = pd.read_csv(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load dataset {dataset_name} for dialect {dialect}: {e}\")\n",
        "        return\n",
        "\n",
        "    if dataset_name not in [\"LogicBenchYN\", \"LogicBenchMCQ\"]:\n",
        "        data = data.drop(columns=[col for col in data.columns if \"BLEU Score\" in col], errors=\"ignore\")\n",
        "\n",
        "    if model_name in model_output_mapping:\n",
        "        model_output_dir = os.path.join(model_output_mapping[model_name], dialect, dataset_name)\n",
        "    else:\n",
        "        model_output_dir = os.path.join(output_base_dir, model_name.replace(\"-\", \"\"), dialect, dataset_name)\n",
        "    os.makedirs(model_output_dir, exist_ok=True)\n",
        "    csv_file = os.path.join(model_output_dir, f\"{dataset_name}_results.csv\")\n",
        "\n",
        "    correct_count = 0\n",
        "    total = 0\n",
        "\n",
        "    if isinstance(data, pd.DataFrame):\n",
        "        total_rows = len(data)\n",
        "    else:\n",
        "        total_rows = len(data)\n",
        "\n",
        "    # COT Prompts\n",
        "\n",
        "    if dataset_name == \"SVAMP\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                problem = row[f\"{dialect} (Original)\"]\n",
        "                question = row[\"Question\"]\n",
        "                expected = str(row[\"Answer\"])\n",
        "                user_prompt = (\n",
        "                    \"Let's carefully reason about this math problem step by step.\\n\"\n",
        "                    f\"Context: {problem}\\nQuestion: {question}\\n\"\n",
        "                    \"Finally, provide your numeric answer as: Answer: <number>\\n\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(.+)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Original)\": problem,\n",
        "                    \"Question\": question,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"MBPP\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows,\n",
        "                    desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                problem = row[f\"{dialect} (Original)\"]\n",
        "                test_cases = row[\"Test_Cases\"]\n",
        "                user_prompt = (\n",
        "                    \"Let's break down the coding problem step by step.\\n\"\n",
        "                    \"Then write a Python function. Output code starting with 'Answer:'\\n\"\n",
        "                    f\"Problem: {problem}\\nTest Cases: {test_cases}\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                generated_code = clean_code(response)\n",
        "                pattern = r\"Answer:\\s*(.+)\"\n",
        "                code = extract_response(generated_code, pattern)\n",
        "                if not code:\n",
        "                    continue\n",
        "                is_correct, error_msg = run_test_cases(code, test_cases, timeout=5)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Original)\": problem,\n",
        "                    \"Code\": code,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Correct\": int(is_correct),\n",
        "                    \"Error Message\": error_msg\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"LogicBenchYN\":\n",
        "        pbar = tqdm(data, total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"task\")\n",
        "        for task in pbar:\n",
        "            try:\n",
        "                context = task[f\"{dialect} (context)\"]\n",
        "                for i in range(1, 5):\n",
        "                    question_key = f\"Question {i}\"\n",
        "                    answer_key = f\"Answer {i}\"\n",
        "                    question = task.get(question_key, \"\")\n",
        "                    expected = task.get(answer_key, \"\")\n",
        "                    if not question or not expected:\n",
        "                        continue\n",
        "                    user_prompt = (\n",
        "                        \"Let's think step by step about whether the answer is yes or no.\\n\"\n",
        "                        f\"Context: {context}\\nQuestion: {question}\\n\"\n",
        "                        \"Finally, respond as: Answer: yes or Answer: no.\\n\"\n",
        "                    )\n",
        "                    system_prompt = \"You are a helpful assistant.\"\n",
        "                    response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                    if response is None:\n",
        "                        continue\n",
        "                    pattern = r\"Answer:\\s*(yes|no)\"\n",
        "                    model_answer = extract_response(response, pattern)\n",
        "                    is_correct = evaluate_response(model_answer, expected)\n",
        "                    total += 1\n",
        "                    if is_correct:\n",
        "                        correct_count += 1\n",
        "                    row_dict = {\n",
        "                        f\"{dialect} (Context)\": context,\n",
        "                        \"Question\": question,\n",
        "                        \"Expected Answer\": expected,\n",
        "                        \"COT Response\": response,\n",
        "                        \"Model Answer\": model_answer,\n",
        "                        \"Correct\": is_correct\n",
        "                    }\n",
        "                    write_row_to_csv(row_dict, csv_file)\n",
        "                    if total % 2 == 0:\n",
        "                        acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                        pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing task: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"LogicBenchMCQ\":\n",
        "        pbar = tqdm(data, total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"task\")\n",
        "        for task in pbar:\n",
        "            try:\n",
        "                context = task[f\"{dialect} (context)\"]\n",
        "                choices = [task.get(f\"Choice {i+1}\", \"\") for i in range(4)]\n",
        "                ground_truth_raw = task.get(\"Answer\", \"\")\n",
        "                gt_digit = parse_gt_to_int(ground_truth_raw)\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                user_prompt = (\n",
        "                    \"Let's analyze each choice step by step.\\n\"\n",
        "                    \"Finally, provide EXACTLY one line: Answer: 1,2,3,or4\\n\\n\"\n",
        "                    f\"Context:\\n{context}\\n\\n\"\n",
        "                    \"Choices:\\n\"\n",
        "                    f\"1) {choices[0]}\\n\"\n",
        "                    f\"2) {choices[1]}\\n\"\n",
        "                    f\"3) {choices[2]}\\n\"\n",
        "                    f\"4) {choices[3]}\\n\"\n",
        "                )\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                predicted_digit = extract_integer_from_response(response)\n",
        "                was_correct = check_mcq_correctness(predicted_digit, gt_digit)\n",
        "                total += 1\n",
        "                if was_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Context)\": context,\n",
        "                    \"Choice 1\": choices[0],\n",
        "                    \"Choice 2\": choices[1],\n",
        "                    \"Choice 3\": choices[2],\n",
        "                    \"Choice 4\": choices[3],\n",
        "                    \"Expected Answer\": ground_truth_raw,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Model Answer\": predicted_digit,\n",
        "                    \"Correct\": was_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing MCQ: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"HumanEVAL\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                prompt_text = row[f\"{dialect} (Prompt)\"]\n",
        "                test_cases = row[\"Test_Cases\"]\n",
        "                user_prompt = (\n",
        "                    \"Let's consider this coding task step by step.\\n\"\n",
        "                    \"Finally, provide Python code starting with 'Answer:'.\\n\\n\"\n",
        "                    f\"Problem: {prompt_text}\\nTest Cases: {test_cases}\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                generated_code = clean_code(response)\n",
        "                pattern = r\"Answer:\\s*(.+)\"\n",
        "                code = extract_response(generated_code, pattern)\n",
        "                if not code:\n",
        "                    continue\n",
        "                is_correct, error_msg = run_test_cases(code, test_cases)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Prompt)\": prompt_text,\n",
        "                    \"Code\": code,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Correct\": int(is_correct),\n",
        "                    \"Error Message\": error_msg\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"GSM8K\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                problem = row[f\"{dialect} (Original)\"]\n",
        "                expected = str(row[\"Answer\"])\n",
        "                user_prompt = (\n",
        "                    \"Let's solve this math word problem step by step.\\n\"\n",
        "                    \"Finally, provide the numeric result as: Answer: <integer or decimal>\\n\\n\"\n",
        "                    f\"Problem: {problem}\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*([0-9.\\-]+)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                if not model_answer:\n",
        "                    pattern_alt = r\"Answer:\\s*([0-9.\\-]+)\"\n",
        "                    match = re.search(pattern_alt, response, re.IGNORECASE)\n",
        "                    if match:\n",
        "                        model_answer = match.group(1)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Original)\": problem,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"FOLIO\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                premises = row[f\"{dialect} (Premises)\"]\n",
        "                conclusion = row[\"Conclusion\"]\n",
        "                expected = row[\"Label\"]\n",
        "                user_prompt = (\n",
        "                    \"Let's analyze whether the conclusion follows.\\n\"\n",
        "                    \"Finally, provide: Answer: True, False, or Uncertain.\\n\\n\"\n",
        "                    f\"Premises: {premises}\\nConclusion: {conclusion}\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(True|False|Uncertain)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Premises)\": premises,\n",
        "                    \"Conclusion\": conclusion,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"WSC\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                paragraph = row[f\"{dialect} (Original Paragraph)\"]\n",
        "                span1 = row[\"Span 1\"]\n",
        "                span2 = row[\"Span 2\"]\n",
        "                expected = str(row[\"Actual Label\"])\n",
        "                user_prompt = (\n",
        "                    \"Let's analyze whether Span 2 refers to Span 1 step by step.\\n\"\n",
        "                    \"Finally, provide Answer: 1 if same, 0 if not.\\n\\n\"\n",
        "                    f\"Paragraph: {paragraph}\\nSpan 1: {span1}\\nSpan 2: {span2}\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(\\d)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Original Paragraph)\": paragraph,\n",
        "                    \"Span 1\": span1,\n",
        "                    \"Span 2\": span2,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"SST-2\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                sentence = row[f\"{dialect} (Original Sentence)\"]\n",
        "                expected = str(row[\"Actual Label\"])\n",
        "                user_prompt = (\n",
        "                    \"Let's analyze the sentiment step by step.\\n\"\n",
        "                    \"Finally, provide: Answer: 1 (positive) or 0 (negative).\\n\\n\"\n",
        "                    f\"Sentence: \\\"{sentence}\\\"\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(\\d)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Original Sentence)\": sentence,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"MultiRC\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                paragraph = row[f\"{dialect} (Paragraph)\"]\n",
        "                question = row[\"Question\"]\n",
        "                answer_choice = row[\"Answer Choice\"]\n",
        "                expected = str(row[\"Actual Label\"])\n",
        "                user_prompt = (\n",
        "                    \"Let's think step by step about the paragraph and question.\\n\"\n",
        "                    \"Finally, provide: Answer: 1 if correct, 0 if incorrect.\\n\\n\"\n",
        "                    f\"Paragraph: {paragraph}\\nQuestion: {question}\\nAnswer Choice: {answer_choice}\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(\\d)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Paragraph)\": paragraph,\n",
        "                    \"Question\": question,\n",
        "                    \"Answer Choice\": answer_choice,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"COPA\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                premise = row[f\"{dialect} (Premise)\"]\n",
        "                choice1 = row[\"Choice 1\"]\n",
        "                choice2 = row[\"Choice 2\"]\n",
        "                expected = str(row[\"Actual Answer\"])\n",
        "                user_prompt = (\n",
        "                    \"Let's think step by step which choice is more plausible.\\n\"\n",
        "                    \"Finally, provide: Answer: 0 (first) or 1 (second).\\n\\n\"\n",
        "                    f\"Premise: {premise}\\nChoice 1: {choice1}\\nChoice 2: {choice2}\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(\\d)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (Premise)\": premise,\n",
        "                    \"Choice 1\": choice1,\n",
        "                    \"Choice 2\": choice2,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"BoolQ\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            try:\n",
        "                passage = row[f\"{dialect} (SAE Passage)\"]\n",
        "                question = row[\"SAE Question\"]\n",
        "                expected = str(row[\"Actual Label\"])\n",
        "                user_prompt = (\n",
        "                    \"Let's analyze this passage carefully.\\n\"\n",
        "                    \"Finally, provide: Answer: TRUE or FALSE.\\n\\n\"\n",
        "                    f\"Passage: \\\"{passage}\\\"\\nQuestion: \\\"{question}\\\"\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                response = prompt_deepseek_model_with_timeout(model_name, system_prompt, user_prompt)\n",
        "                if response is None:\n",
        "                    continue\n",
        "                pattern = r\"Answer:\\s*(TRUE|FALSE)\"\n",
        "                model_answer = extract_response(response, pattern)\n",
        "                if not model_answer:\n",
        "                    pattern_alt = r\"Answer:\\s*(TRUE|FALSE)\"\n",
        "                    match = re.search(pattern_alt, str(response), re.IGNORECASE)\n",
        "                    if match:\n",
        "                        model_answer = match.group(1).upper()\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (SAE Passage)\": passage,\n",
        "                    \"SAE Question\": question,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"COT Response\": response,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row: {e}\")\n",
        "                continue\n",
        "        pbar.close()\n",
        "\n",
        "    else:\n",
        "        print(f\"Dataset {dataset_name} not recognized for processing.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        accuracy = (correct_count / total * 100) if total > 0 else 0\n",
        "        with open(os.path.join(model_output_dir, f\"{dataset_name}_accuracy.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"Total instances: {total}\\n\")\n",
        "            f.write(f\"Correct answers: {correct_count}\\n\")\n",
        "            f.write(f\"Accuracy: {accuracy:.2f}%\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing accuracy file for dataset {dataset_name}: {e}\")\n",
        "\n",
        "for model in models:\n",
        "    for dialect in dialects:\n",
        "        for dataset_name, rel_path in datasets.items():\n",
        "            full_path = os.path.join(input_base_dir, dialect, rel_path)\n",
        "            if os.path.exists(full_path):\n",
        "                process_dataset(model, dataset_name, full_path, dialect)\n",
        "            else:\n",
        "                print(f\"File not found: {full_path}\")\n",
        "\n",
        "print(\"CoT evaluation complete! Results have been saved.\")\n",
        "try:\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()\n",
        "except ImportError:\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
