{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y9q_F48kiVbO"
      },
      "outputs": [],
      "source": [
        "## NON-COT EVALS\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install together pandas numpy regex tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from together import Together\n",
        "from together.error import RateLimitError, APIError\n",
        "\n",
        "TOGETHER_API_KEY = \"API-KEY\"\n",
        "client = Together(api_key=TOGETHER_API_KEY)\n",
        "\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "input_base_dir = \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o\"\n",
        "output_base_dir = \"/content/drive/MyDrive/!!Multi-AAVENUE/Evaluation Results/NonCOT_Evals\"\n",
        "noncot_output_dir = os.path.join(output_base_dir, \"LLaMa_3_8b_Instruct_Test_NonCOT\")\n",
        "\n",
        "dialects = [\"IndE\", \"JamE\", \"AAVE\", \"CollSgE\", \"ChcE\"]\n",
        "\n",
        "datasets = {\n",
        "    \"SVAMP\": \"SVAMP(700)/SVAMP(700)_filtered_bleu_scores.csv\",\n",
        "    \"MBPP\": \"MBPP(374)/MBPP(374)_filtered_bleu_scores.csv\",\n",
        "    \"LogicBenchYN\": \"Logic Bench YN(500)/Logic Bench YN(500)_filtered_bleu_scores.json\",\n",
        "    \"LogicBenchMCQ\": \"Logic Bench MCQ(480)/Logic Bench MCQ(480)_filtered_bleu_scores.json\",\n",
        "    \"HumanEVAL\": \"HumanEVAL(164)/HumanEVAL(164)_filtered_bleu_scores.csv\",\n",
        "    \"GSM8K\": \"GSM8K(1000)/GSM8K(1000)_filtered_bleu_scores.csv\",\n",
        "    \"FOLIO\": \"FOLIO(1000)/FOLIO(1000)_filtered_bleu_scores.csv\",\n",
        "    \"WSC\": \"GLUE + SuperGLUE/WSC (659)/WSC (659)_filtered_bleu_scores.csv\",\n",
        "    \"SST-2\": \"GLUE + SuperGLUE/SST-2 (1000)/SST-2 (1000)_filtered_bleu_scores.csv\",\n",
        "    \"MultiRC\": \"GLUE + SuperGLUE/MultiRC (1000)/MultiRC (1000)_filtered_bleu_scores.csv\",\n",
        "    \"COPA\": \"GLUE + SuperGLUE/COPA (500)/COPA (500)_filtered_bleu_scores.csv\",\n",
        "    \"BoolQ\": \"GLUE + SuperGLUE/BoolQ (1000)/BoolQ (1000)_filtered_bleu_scores.csv\"\n",
        "}\n",
        "\n",
        "models = [\"meta-llama/Meta-Llama-3-8B-Instruct-Turbo\"]\n",
        "\n",
        "def write_row_to_csv(row: dict, filename: str):\n",
        "    mode = 'a'\n",
        "    with open(filename, mode, newline='', encoding=\"utf-8\") as csvfile:\n",
        "        df = pd.DataFrame([row])\n",
        "        write_header = csvfile.tell() == 0\n",
        "        df.to_csv(csvfile, index=False, header=write_header)\n",
        "        csvfile.flush()\n",
        "\n",
        "def prompt_together_model(model_name: str, system_message: str, user_message: str, retries=5, backoff_factor=2):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_message},\n",
        "                    {\"role\": \"user\", \"content\": user_message}\n",
        "                ],\n",
        "                temperature=TEMPERATURE,\n",
        "                max_tokens=2048\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except (RateLimitError, APIError) as e:\n",
        "            wait_time = backoff_factor ** attempt\n",
        "            print(f\"API error: {e}. Retrying in {wait_time} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "    raise Exception(\"Maximum retries exceeded.\")\n",
        "\n",
        "def clean_code(generated_code: str) -> str:\n",
        "    cleaned_code = re.sub(r\"```(?:python)?\", \"\", generated_code, flags=re.DOTALL)\n",
        "    cleaned_code = re.sub(r\"```\", \"\", cleaned_code, flags=re.DOTALL)\n",
        "    return cleaned_code.strip()\n",
        "\n",
        "def extract_response(response: str, pattern: str) -> str:\n",
        "    match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)\n",
        "    return match.group(1).strip() if match else \"\"\n",
        "\n",
        "def evaluate_response(model_answer: str, expected_answer: str) -> bool:\n",
        "    return model_answer.strip().lower() == expected_answer.strip().lower()\n",
        "\n",
        "def run_test_cases(generated_code: str, test_cases: str):\n",
        "    try:\n",
        "        exec_globals = {}\n",
        "        exec(generated_code, exec_globals)\n",
        "        exec(test_cases, exec_globals)\n",
        "        return True, \"\"\n",
        "    except AssertionError as e:\n",
        "        return False, f\"AssertionError: {str(e)}\"\n",
        "    except SyntaxError as e:\n",
        "        return False, f\"SyntaxError: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        return False, f\"RuntimeError: {str(e)}\"\n",
        "\n",
        "model_output_mapping = {\n",
        "    \"meta-llama/Meta-Llama-3-8B-Instruct-Turbo\": os.path.join(noncot_output_dir, \"LLaMa_3_8b_Instruct_Test_NonCOT\")\n",
        "}\n",
        "\n",
        "def process_dataset(model_name: str, dataset_name: str, file_path: str, dialect: str):\n",
        "    if dataset_name in [\"LogicBenchYN\", \"LogicBenchMCQ\"]:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "    else:\n",
        "        data = pd.read_csv(file_path)\n",
        "\n",
        "    if dataset_name not in [\"LogicBenchYN\", \"LogicBenchMCQ\"]:\n",
        "        data = data.drop(columns=[col for col in data.columns if \"BLEU Score\" in col], errors=\"ignore\")\n",
        "\n",
        "    model_output_dir = os.path.join(model_output_mapping[model_name], dialect, dataset_name)\n",
        "    os.makedirs(model_output_dir, exist_ok=True)\n",
        "    csv_file = os.path.join(model_output_dir, f\"{dataset_name}_results.csv\")\n",
        "\n",
        "    correct_count = 0\n",
        "    total = 0\n",
        "    total_rows = len(data)\n",
        "\n",
        "    if dataset_name == \"SVAMP\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            problem = row.get(f\"{dialect} (Original)\", \"\")\n",
        "            question = row.get(\"Question\", \"\")\n",
        "            expected = str(row.get(\"Answer\", \"\"))\n",
        "\n",
        "            # Non-CoT prompt: no \"step by step\" or \"chain-of-thought\" mention\n",
        "            user_prompt = (\n",
        "                \"Given a mathematics problem, determine the answer. \"\n",
        "                \"Simplify your answer as much as possible and provide a final numeric answer.\\n\"\n",
        "                f\"Context: {problem}\\n\"\n",
        "                f\"Question: {question}\\n\"\n",
        "                \"Final Numeric Answer: \"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Final Numeric Answer:\\s*([0-9.\\-]+)\"\n",
        "            model_answer = extract_response(full_response, pattern)\n",
        "            if not model_answer:\n",
        "                model_answer = \"N/A\"\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Original)\": problem,\n",
        "                \"Question\": question,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"MBPP\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            problem = row.get(f\"{dialect} (Original)\", \"\")\n",
        "            test_cases = row.get(\"Test_Cases\", \"\")\n",
        "            user_prompt = (\n",
        "                \"Given a coding problem, produce a Python function that solves the problem. \"\n",
        "                \"Provide your entire code. Start it with 'Answer:' on its own line.\\n\"\n",
        "                f\"Problem: {problem}\\n\"\n",
        "                f\"Test Cases: {test_cases}\\n\"\n",
        "                \"Answer:\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            code_block = clean_code(full_response)\n",
        "            pattern = r\"Answer:\\s*(.+)\"\n",
        "            code = extract_response(code_block, pattern)\n",
        "            passed, err_msg = run_test_cases(code, test_cases)\n",
        "            total += 1\n",
        "            if passed:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Original)\": problem,\n",
        "                \"Code\": code,\n",
        "                \"Correct\": int(passed),\n",
        "                \"Error Message\": err_msg\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"LogicBenchMCQ\":\n",
        "        def parse_gt_to_int(gt: str) -> str:\n",
        "            match = re.search(r\"choice_(\\d+)\", gt, re.IGNORECASE)\n",
        "            if match:\n",
        "                return match.group(1)\n",
        "            match2 = re.search(r\"\\d+\", gt)\n",
        "            if match2:\n",
        "                return match2.group(0)\n",
        "            return \"\"\n",
        "\n",
        "        def extract_integer_from_response(response_text: str) -> str:\n",
        "            match = re.search(r\"Final Answer:\\s*(\\d+)\", response_text)\n",
        "            if match:\n",
        "                return match.group(1).strip()\n",
        "            return \"\"\n",
        "\n",
        "        pbar = tqdm(data, total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for task in pbar:\n",
        "            context = task.get(f\"{dialect} (context)\", \"\")\n",
        "            choices = [\n",
        "                task.get(\"Choice 1\", \"\"),\n",
        "                task.get(\"Choice 2\", \"\"),\n",
        "                task.get(\"Choice 3\", \"\"),\n",
        "                task.get(\"Choice 4\", \"\"),\n",
        "            ]\n",
        "            ground_truth_raw = task.get(\"Answer\", \"\")\n",
        "            if not context or not all(choices) or not ground_truth_raw:\n",
        "                row_dict = {\n",
        "                    \"Dialect\": dialect,\n",
        "                    \"Context\": context,\n",
        "                    \"Choice 1\": choices[0],\n",
        "                    \"Choice 2\": choices[1],\n",
        "                    \"Choice 3\": choices[2],\n",
        "                    \"Choice 4\": choices[3],\n",
        "                    \"Expected Answer\": \"N/A (incomplete data)\",\n",
        "                    \"Model Answer\": \"N/A (incomplete data)\",\n",
        "                    \"Correct\": False\n",
        "                }\n",
        "                pd.DataFrame([row_dict]).to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n",
        "                continue\n",
        "            gt_digit = parse_gt_to_int(ground_truth_raw)\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            user_prompt = (\n",
        "                \"Given a context and four choices, pick the correct choice number (1, 2, 3, or 4). \"\n",
        "                \"Provide your final answer as: Final Answer: X\\n\\n\"\n",
        "                f\"Context:\\n{context}\\n\\n\"\n",
        "                \"Choices:\\n\"\n",
        "                f\"1) {choices[0]}\\n\"\n",
        "                f\"2) {choices[1]}\\n\"\n",
        "                f\"3) {choices[2]}\\n\"\n",
        "                f\"4) {choices[3]}\\n\"\n",
        "                \"Final Answer:\"\n",
        "            )\n",
        "            response_text = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            predicted_digit = extract_integer_from_response(response_text)\n",
        "            if not predicted_digit:\n",
        "                predicted_digit = \"N/A\"\n",
        "            is_correct = (predicted_digit == gt_digit and bool(gt_digit))\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                \"Dialect\": dialect,\n",
        "                \"Context\": context,\n",
        "                \"Choice 1\": choices[0],\n",
        "                \"Choice 2\": choices[1],\n",
        "                \"Choice 3\": choices[2],\n",
        "                \"Choice 4\": choices[3],\n",
        "                \"Expected Answer\": ground_truth_raw,\n",
        "                \"Model Answer\": predicted_digit,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            pd.DataFrame([row_dict]).to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n",
        "            acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "            pbar.set_postfix({\"Acc\": f\"{acc_percentage:.1f}%\"})\n",
        "        pbar.close()\n",
        "        df_processed = pd.read_csv(csv_file)\n",
        "        df_processed.to_csv(csv_file, index=False)\n",
        "\n",
        "    elif dataset_name == \"HumanEVAL\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            prompt_text = row.get(f\"{dialect} (Prompt)\", \"\")\n",
        "            test_cases = row.get(\"Test_Cases\", \"\")\n",
        "            user_prompt = (\n",
        "                \"Given a coding problem, produce a Python function that solves the problem. \"\n",
        "                \"Provide your entire code in 'Answer:'.\\n\"\n",
        "                f\"Problem: {prompt_text}\\n\"\n",
        "                f\"Test Cases: {test_cases}\\n\"\n",
        "                \"Answer:\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            generated_code = clean_code(response)\n",
        "            pattern = r\"Answer:\\s*(.+)\"\n",
        "            code = extract_response(generated_code, pattern)\n",
        "            is_correct, error_msg = run_test_cases(code, test_cases)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Prompt)\": prompt_text,\n",
        "                \"Code\": code,\n",
        "                \"Correct\": int(is_correct),\n",
        "                \"Error Message\": error_msg\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"WSC\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            paragraph = row.get(f\"{dialect} (Original Paragraph)\", \"\")\n",
        "            span1 = row.get(\"Span 1\", \"\")\n",
        "            span2 = row.get(\"Span 2\", \"\")\n",
        "            expected = str(row.get(\"Actual Label\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Given a pronoun resolution problem, determine whether Span 2 refers to Span 1. \"\n",
        "                \"Provide 1 if they refer, 0 if they do not, in 'Final Answer:'.\\n\"\n",
        "                f\"Paragraph: {paragraph}\\n\"\n",
        "                f\"Span 1: {span1}\\n\"\n",
        "                f\"Span 2: {span2}\\n\"\n",
        "                \"Final Answer:\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Final Answer:\\s*(\\d)\"\n",
        "            model_answer = extract_response(full_response, pattern)\n",
        "            if not model_answer:\n",
        "                model_answer = \"N/A\"\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Original Paragraph)\": paragraph,\n",
        "                \"Span 1\": span1,\n",
        "                \"Span 2\": span2,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"GSM8K\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            problem = row.get(f\"{dialect} (Original)\", \"\")\n",
        "            expected = str(row.get(\"Answer\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Given a mathematics problem, provide a final numeric answer without decimals.\\n\"\n",
        "                f\"Problem: {problem}\\n\"\n",
        "                \"Final Numeric Answer:\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Final Numeric Answer:\\s*([0-9.\\-]+)\"\n",
        "            model_answer = extract_response(full_response, pattern)\n",
        "            if not model_answer:\n",
        "                model_answer = \"N/A\"\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Original)\": problem,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"FOLIO\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            premises = row.get(f\"{dialect} (Premises)\", \"\")\n",
        "            conclusion = row.get(\"Conclusion\", \"\")\n",
        "            expected = row.get(\"Label\", \"\")\n",
        "            user_prompt = (\n",
        "                \"Given premises and a conclusion, determine whether the conclusion is True or False. \"\n",
        "                \"Provide your final answer in 'Final Answer: True' or 'Final Answer: False'.\\n\"\n",
        "                f\"Premises: {premises}\\n\"\n",
        "                f\"Conclusion: {conclusion}\\n\"\n",
        "                \"Final Answer:\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Final Answer:\\s*(True|False)\"\n",
        "            model_answer = extract_response(full_response, pattern)\n",
        "            if not model_answer:\n",
        "                model_answer = \"N/A\"\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Premises)\": premises,\n",
        "                \"Conclusion\": conclusion,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"LogicBenchYN\":\n",
        "        pbar = tqdm(data, total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for task in pbar:\n",
        "            context = task.get(f\"{dialect} (context)\", \"\")\n",
        "            for i in range(1, 5):\n",
        "                question_key = f\"Question {i}\"\n",
        "                answer_key = f\"Answer {i}\"\n",
        "                question = task.get(question_key, \"\")\n",
        "                expected = task.get(answer_key, \"\")\n",
        "                if not question or not expected:\n",
        "                    continue\n",
        "                user_prompt = (\n",
        "                    \"Given a yes/no question, answer yes or no. Provide your final answer as 'Final Answer: yes' or 'Final Answer: no'.\\n\"\n",
        "                    f\"Context: {context}\\n\"\n",
        "                    f\"Question: {question}\\n\"\n",
        "                    \"Final Answer:\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "                pattern = r\"Final Answer:\\s*(yes|no)\"\n",
        "                model_answer = extract_response(full_response, pattern)\n",
        "                if not model_answer:\n",
        "                    model_answer = \"N/A\"\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                total += 1\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (context)\": context,\n",
        "                    \"Question\": question,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"SST-2\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            sentence = row.get(f\"{dialect} (Original Sentence)\", \"\")\n",
        "            expected = str(row.get(\"Actual Label\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Given a sentence, determine its sentiment (1 for positive, 0 for negative). \"\n",
        "                \"Provide your final answer as: Answer: 1 or Answer: 0.\\n\"\n",
        "                f\"Sentence: {sentence}\\n\"\n",
        "                \"Answer:\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Answer:\\s*(\\d)\"\n",
        "            model_answer = extract_response(response, pattern)\n",
        "            if not model_answer:\n",
        "                pattern_alt = r\"Answer:\\s*(\\d)\"\n",
        "                match = re.search(pattern_alt, response, re.IGNORECASE)\n",
        "                if match:\n",
        "                    model_answer = match.group(1)\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Original Sentence)\": sentence,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"MultiRC\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            paragraph = row.get(f\"{dialect} (Paragraph)\", \"\")\n",
        "            question = row.get(\"Question\", \"\")\n",
        "            answer_choice = row.get(\"Answer Choice\", \"\")\n",
        "            expected = str(row.get(\"Actual Label\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Given a paragraph, question, and an answer choice, determine if the answer choice is correct (1) or incorrect (0). \"\n",
        "                \"Provide your final answer as: Answer: 1 or Answer: 0.\\n\"\n",
        "                f\"Paragraph: {paragraph}\\n\"\n",
        "                f\"Question: {question}\\n\"\n",
        "                f\"Answer Choice: {answer_choice}\\n\"\n",
        "                \"Answer:\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Answer:\\s*(\\d)\"\n",
        "            model_answer = extract_response(response, pattern)\n",
        "            if not model_answer:\n",
        "                pattern_alt = r\"Answer:\\s*(\\d)\"\n",
        "                match = re.search(pattern_alt, response, re.IGNORECASE)\n",
        "                if match:\n",
        "                    model_answer = match.group(1)\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Paragraph)\": paragraph,\n",
        "                \"Question\": question,\n",
        "                \"Answer Choice\": answer_choice,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"} )\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"COPA\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            premise = row.get(f\"{dialect} (Premise)\", \"\")\n",
        "            choice1 = row.get(\"Choice 1\", \"\")\n",
        "            choice2 = row.get(\"Choice 2\", \"\")\n",
        "            expected = str(row.get(\"Actual Answer\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Given a premise and two choices, pick which choice (0 or 1) is more plausible. \"\n",
        "                \"Provide your final answer as: Answer: 0 or Answer: 1.\\n\"\n",
        "                f\"Premise: {premise}\\n\"\n",
        "                f\"Choice 1: {choice1}\\n\"\n",
        "                f\"Choice 2: {choice2}\\n\"\n",
        "                \"Answer:\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Answer:\\s*(\\d)\"\n",
        "            model_answer = extract_response(response, pattern)\n",
        "            if not model_answer:\n",
        "                pattern_alt = r\"Answer:\\s*(\\d)\"\n",
        "                match = re.search(pattern_alt, response, re.IGNORECASE)\n",
        "                if match:\n",
        "                    model_answer = match.group(1)\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Premise)\": premise,\n",
        "                \"Choice 1\": choice1,\n",
        "                \"Choice 2\": choice2,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"} )\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"BoolQ\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            passage = row.get(f\"{dialect} (SAE Passage)\", \"\")\n",
        "            question = row.get(\"SAE Question\", \"\")\n",
        "            expected = str(row.get(\"Actual Label\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Given a passage and a yes/no question, label it as TRUE or FALSE. \"\n",
        "                \"Provide your final answer in 'Answer: TRUE' or 'Answer: FALSE'.\\n\"\n",
        "                f\"Passage: {passage}\\n\"\n",
        "                f\"Question: {question}\\n\"\n",
        "                \"Answer:\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Answer:\\s*(TRUE|FALSE)\"\n",
        "            model_answer = extract_response(response, pattern)\n",
        "            if not model_answer:\n",
        "                pattern_alt = r\"Answer:\\s*(TRUE|FALSE)\"\n",
        "                match = re.search(pattern_alt, response, re.IGNORECASE)\n",
        "                if match:\n",
        "                    model_answer = match.group(1).upper()\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (SAE Passage)\": passage,\n",
        "                \"SAE Question\": question,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"} )\n",
        "        pbar.close()\n",
        "\n",
        "    else:\n",
        "        print(f\"Dataset {dataset_name} not recognized for processing.\")\n",
        "        return\n",
        "\n",
        "    accuracy = (correct_count / total * 100) if total > 0 else 0\n",
        "    with open(os.path.join(model_output_dir, f\"{dataset_name}_accuracy.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"Total instances: {total}\\n\")\n",
        "        f.write(f\"Correct answers: {correct_count}\\n\")\n",
        "        f.write(f\"Accuracy: {accuracy:.2f}%\\n\")\n",
        "\n",
        "def main():\n",
        "    for model in models:\n",
        "        for dialect in dialects:\n",
        "            for dataset_name, rel_path in datasets.items():\n",
        "                full_path = os.path.join(input_base_dir, dialect, rel_path)\n",
        "                if os.path.exists(full_path):\n",
        "                    process_dataset(model, dataset_name, full_path, dialect)\n",
        "                else:\n",
        "                    print(f\"⚠️ Missing file: {full_path}\")\n",
        "    print(\"✅ Evaluation complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## COT EVALS\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install together pandas numpy regex tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from together import Together\n",
        "from together.error import RateLimitError, APIError\n",
        "\n",
        "TOGETHER_API_KEY = \"API-KEY\"\n",
        "client = Together(api_key=TOGETHER_API_KEY)\n",
        "\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "input_base_dir = \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o\"\n",
        "output_base_dir = \"/content/drive/MyDrive/!!Multi-AAVENUE/Evaluation Results/COT Evals\"\n",
        "cot_output_dir = os.path.join(output_base_dir, \"LLaMa_3_8b_Instruct_Test_CoT\")\n",
        "\n",
        "dialects = [\"IndE\", \"JamE\", \"AAVE\", \"CollSgE\", \"ChcE\"]\n",
        "\n",
        "datasets = {\n",
        "    \"SVAMP\": \"SVAMP(700)/SVAMP(700)_filtered_bleu_scores.csv\",\n",
        "    \"MBPP\": \"MBPP(374)/MBPP(374)_filtered_bleu_scores.csv\",\n",
        "    \"LogicBenchYN\": \"Logic Bench YN(500)/Logic Bench YN(500)_filtered_bleu_scores.json\",\n",
        "    \"LogicBenchMCQ\": \"Logic Bench MCQ(480)/Logic Bench MCQ(480)_filtered_bleu_scores.json\",\n",
        "    \"HumanEVAL\": \"HumanEVAL(164)/HumanEVAL(164)_filtered_bleu_scores.csv\",\n",
        "    \"GSM8K\": \"GSM8K(1000)/GSM8K(1000)_filtered_bleu_scores.csv\",\n",
        "    \"FOLIO\": \"FOLIO(1000)/FOLIO(1000)_filtered_bleu_scores.csv\",\n",
        "    \"WSC\": \"GLUE + SuperGLUE/WSC (659)/WSC (659)_filtered_bleu_scores.csv\",\n",
        "    \"SST-2\": \"GLUE + SuperGLUE/SST-2 (1000)/SST-2 (1000)_filtered_bleu_scores.csv\",\n",
        "    \"MultiRC\": \"GLUE + SuperGLUE/MultiRC (1000)/MultiRC (1000)_filtered_bleu_scores.csv\",\n",
        "    \"COPA\": \"GLUE + SuperGLUE/COPA (500)/COPA (500)_filtered_bleu_scores.csv\",\n",
        "    \"BoolQ\": \"GLUE + SuperGLUE/BoolQ (1000)/BoolQ (1000)_filtered_bleu_scores.csv\"\n",
        "}\n",
        "\n",
        "models = [\"meta-llama/Meta-Llama-3-8B-Instruct-Turbo\"]\n",
        "\n",
        "def write_row_to_csv(row: dict, filename: str):\n",
        "    mode = 'a'\n",
        "    with open(filename, mode, newline='', encoding=\"utf-8\") as csvfile:\n",
        "        df = pd.DataFrame([row])\n",
        "        write_header = csvfile.tell() == 0\n",
        "        df.to_csv(csvfile, index=False, header=write_header)\n",
        "        csvfile.flush()\n",
        "\n",
        "def prompt_together_model(model_name: str, system_message: str, user_message: str, retries=5, backoff_factor=2):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_message},\n",
        "                    {\"role\": \"user\", \"content\": user_message}\n",
        "                ],\n",
        "                temperature=TEMPERATURE,\n",
        "                max_tokens=2048\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except (RateLimitError, APIError) as e:\n",
        "            wait_time = backoff_factor ** attempt\n",
        "            print(f\"API error: {e}. Retrying in {wait_time} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "    raise Exception(\"Maximum retries exceeded.\")\n",
        "\n",
        "def clean_code(generated_code: str) -> str:\n",
        "    cleaned_code = re.sub(r\"```(?:python)?\", \"\", generated_code, flags=re.DOTALL)\n",
        "    cleaned_code = re.sub(r\"```\", \"\", cleaned_code, flags=re.DOTALL)\n",
        "    return cleaned_code.strip()\n",
        "\n",
        "def extract_response(response: str, pattern: str) -> str:\n",
        "    match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)\n",
        "    return match.group(1).strip() if match else \"\"\n",
        "\n",
        "def evaluate_response(model_answer: str, expected_answer: str) -> bool:\n",
        "    return model_answer.strip().lower() == expected_answer.strip().lower()\n",
        "\n",
        "def run_test_cases(generated_code: str, test_cases: str):\n",
        "    try:\n",
        "        exec_globals = {}\n",
        "        exec(generated_code, exec_globals)\n",
        "        exec(test_cases, exec_globals)\n",
        "        return True, \"\"\n",
        "    except AssertionError as e:\n",
        "        return False, f\"AssertionError: {str(e)}\"\n",
        "    except SyntaxError as e:\n",
        "        return False, f\"SyntaxError: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        return False, f\"RuntimeError: {str(e)}\"\n",
        "\n",
        "model_output_mapping = {\n",
        "    \"meta-llama/Meta-Llama-3-8B-Instruct-Turbo\": os.path.join(cot_output_dir, \"LLaMa_3_8b_Instruct_Test_CoT\")\n",
        "}\n",
        "\n",
        "def process_dataset(model_name: str, dataset_name: str, file_path: str, dialect: str):\n",
        "    if dataset_name in [\"LogicBenchYN\", \"LogicBenchMCQ\"]:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "    else:\n",
        "        data = pd.read_csv(file_path)\n",
        "\n",
        "    if dataset_name not in [\"LogicBenchYN\", \"LogicBenchMCQ\"]:\n",
        "        data = data.drop(columns=[col for col in data.columns if \"BLEU Score\" in col], errors=\"ignore\")\n",
        "\n",
        "    model_output_dir = os.path.join(model_output_mapping[model_name], dialect, dataset_name)\n",
        "    os.makedirs(model_output_dir, exist_ok=True)\n",
        "    csv_file = os.path.join(model_output_dir, f\"{dataset_name}_results.csv\")\n",
        "\n",
        "    correct_count = 0\n",
        "    total = 0\n",
        "    total_rows = len(data)\n",
        "\n",
        "    # Chain-of-thought versions of prompts\n",
        "\n",
        "    if dataset_name == \"SVAMP\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            problem = row.get(f\"{dialect} (Original)\", \"\")\n",
        "            question = row.get(\"Question\", \"\")\n",
        "            expected = str(row.get(\"Answer\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Let's think about this step by step to solve the math problem. \"\n",
        "                \"Then provide:\\nFinal Numeric Answer: <the final integer or decimal>\\n\\n\"\n",
        "                f\"Context: {problem}\\n\"\n",
        "                f\"Question: {question}\\n\"\n",
        "                \"No extra text after the numeric answer.\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Final Numeric Answer:\\s*([0-9.\\-]+)\"\n",
        "            model_answer = extract_response(full_response, pattern)\n",
        "            if not model_answer:\n",
        "                model_answer = \"N/A\"\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Original)\": problem,\n",
        "                \"Question\": question,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"COT Response\": full_response,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"MBPP\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            problem = row.get(f\"{dialect} (Original)\", \"\")\n",
        "            test_cases = row.get(\"Test_Cases\", \"\")\n",
        "            user_prompt = (\n",
        "                \"Let's think step by step about how to solve this coding task. \"\n",
        "                \"Then write the final Python function. \"\n",
        "                \"Output only Python code starting with 'Answer:'\\n\"\n",
        "                f\"Problem: {problem}\\n\"\n",
        "                f\"Test Cases: {test_cases}\\n\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            code_block = clean_code(response)\n",
        "            pattern = r\"Answer:\\s*(.+)\"\n",
        "            code = extract_response(code_block, pattern)\n",
        "            passed, err_msg = run_test_cases(code, test_cases)\n",
        "            total += 1\n",
        "            if passed:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Original)\": problem,\n",
        "                \"Code\": code,\n",
        "                \"COT Response\": response,\n",
        "                \"Correct\": int(passed),\n",
        "                \"Error Message\": err_msg\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"LogicBenchMCQ\":\n",
        "        def parse_gt_to_int(gt: str) -> str:\n",
        "            match = re.search(r\"choice_(\\d+)\", gt, re.IGNORECASE)\n",
        "            if match:\n",
        "                return match.group(1)\n",
        "            match2 = re.search(r\"\\d+\", gt)\n",
        "            if match2:\n",
        "                return match2.group(0)\n",
        "            return \"\"\n",
        "\n",
        "        def extract_integer_from_response(response_text: str) -> str:\n",
        "            match = re.search(r\"Final Answer:\\s*(\\d+)\", response_text)\n",
        "            if match:\n",
        "                return match.group(1).strip()\n",
        "            return \"\"\n",
        "\n",
        "        pbar = tqdm(data, total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for task in pbar:\n",
        "            context = task.get(f\"{dialect} (context)\", \"\")\n",
        "            choices = [\n",
        "                task.get(\"Choice 1\", \"\"),\n",
        "                task.get(\"Choice 2\", \"\"),\n",
        "                task.get(\"Choice 3\", \"\"),\n",
        "                task.get(\"Choice 4\", \"\"),\n",
        "            ]\n",
        "            ground_truth_raw = task.get(\"Answer\", \"\")\n",
        "            if not context or not all(choices) or not ground_truth_raw:\n",
        "                row_dict = {\n",
        "                    \"Dialect\": dialect,\n",
        "                    \"Context\": context,\n",
        "                    \"Choice 1\": choices[0],\n",
        "                    \"Choice 2\": choices[1],\n",
        "                    \"Choice 3\": choices[2],\n",
        "                    \"Choice 4\": choices[3],\n",
        "                    \"Expected Answer\": \"N/A (incomplete data)\",\n",
        "                    \"COT Response\": \"N/A\",\n",
        "                    \"Model Answer\": \"N/A\",\n",
        "                    \"Correct\": False\n",
        "                }\n",
        "                pd.DataFrame([row_dict]).to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n",
        "                continue\n",
        "            gt_digit = parse_gt_to_int(ground_truth_raw)\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            user_prompt = (\n",
        "                \"Let's analyze this context and each choice step by step. \"\n",
        "                \"Finally, provide: 'Final Answer: X' with no extra text.\\n\"\n",
        "                f\"Context:\\n{context}\\n\\n\"\n",
        "                \"Choices:\\n\"\n",
        "                f\"1) {choices[0]}\\n\"\n",
        "                f\"2) {choices[1]}\\n\"\n",
        "                f\"3) {choices[2]}\\n\"\n",
        "                f\"4) {choices[3]}\\n\"\n",
        "            )\n",
        "            response_text = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            predicted_digit = extract_integer_from_response(response_text)\n",
        "            if not predicted_digit:\n",
        "                predicted_digit = \"N/A\"\n",
        "            is_correct = (predicted_digit == gt_digit and bool(gt_digit))\n",
        "            nonlocal_total = 1\n",
        "            total += nonlocal_total\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                \"Dialect\": dialect,\n",
        "                \"Context\": context,\n",
        "                \"Choice 1\": choices[0],\n",
        "                \"Choice 2\": choices[1],\n",
        "                \"Choice 3\": choices[2],\n",
        "                \"Choice 4\": choices[3],\n",
        "                \"Expected Answer\": ground_truth_raw,\n",
        "                \"COT Response\": response_text,\n",
        "                \"Model Answer\": predicted_digit,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            pd.DataFrame([row_dict]).to_csv(csv_file, mode='a', index=False, header=not os.path.exists(csv_file))\n",
        "            acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "            pbar.set_postfix({\"Acc\": f\"{acc_percentage:.1f}%\"})\n",
        "        pbar.close()\n",
        "        df_processed = pd.read_csv(csv_file)\n",
        "        df_processed.to_csv(csv_file, index=False)\n",
        "\n",
        "    elif dataset_name == \"HumanEVAL\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            prompt_text = row.get(f\"{dialect} (Prompt)\", \"\")\n",
        "            test_cases = row.get(\"Test_Cases\", \"\")\n",
        "            user_prompt = (\n",
        "                \"Let's break down the coding problem step by step, then provide the final Python code. \"\n",
        "                \"Code should start with 'Answer:'.\\n\"\n",
        "                f\"Problem: {prompt_text}\\n\"\n",
        "                f\"Test Cases: {test_cases}\\n\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            code_block = clean_code(response)\n",
        "            pattern = r\"Answer:\\s*(.+)\"\n",
        "            code = extract_response(code_block, pattern)\n",
        "            is_correct, error_msg = run_test_cases(code, test_cases)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Prompt)\": prompt_text,\n",
        "                \"Code\": code,\n",
        "                \"COT Response\": response,\n",
        "                \"Correct\": int(is_correct),\n",
        "                \"Error Message\": error_msg\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"WSC\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            paragraph = row.get(f\"{dialect} (Original Paragraph)\", \"\")\n",
        "            span1 = row.get(\"Span 1\", \"\")\n",
        "            span2 = row.get(\"Span 2\", \"\")\n",
        "            expected = str(row.get(\"Actual Label\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Let's analyze whether Span 2 refers to Span 1 step by step. \"\n",
        "                \"Finally, provide 'Final Answer: 1' if yes, 'Final Answer: 0' if no.\\n\"\n",
        "                f\"Paragraph: {paragraph}\\n\"\n",
        "                f\"Span 1: {span1}\\n\"\n",
        "                f\"Span 2: {span2}\\n\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Final Answer:\\s*(\\d)\"\n",
        "            model_answer = extract_response(full_response, pattern)\n",
        "            if not model_answer:\n",
        "                model_answer = \"N/A\"\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Original Paragraph)\": paragraph,\n",
        "                \"Span 1\": span1,\n",
        "                \"Span 2\": span2,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"COT Response\": full_response,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"GSM8K\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            problem = row.get(f\"{dialect} (Original)\", \"\")\n",
        "            expected = str(row.get(\"Answer\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Let's think about the math problem step by step. \"\n",
        "                \"Finally, provide:\\nFinal Numeric Answer: <the integer>\\n\\n\"\n",
        "                f\"Problem: {problem}\\n\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Final Numeric Answer:\\s*([0-9.\\-]+)\"\n",
        "            model_answer = extract_response(full_response, pattern)\n",
        "            if not model_answer:\n",
        "                model_answer = \"N/A\"\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Original)\": problem,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"COT Response\": full_response,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"FOLIO\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            premises = row.get(f\"{dialect} (Premises)\", \"\")\n",
        "            conclusion = row.get(\"Conclusion\", \"\")\n",
        "            expected = row.get(\"Label\", \"\")\n",
        "            user_prompt = (\n",
        "                \"Let's evaluate whether the conclusion follows from the premises step by step. \"\n",
        "                \"Finally, provide:\\nFinal Answer: True or False\\n\\n\"\n",
        "                f\"Premises: {premises}\\n\"\n",
        "                f\"Conclusion: {conclusion}\\n\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Final Answer:\\s*(True|False)\"\n",
        "            model_answer = extract_response(full_response, pattern)\n",
        "            if not model_answer:\n",
        "                model_answer = \"N/A\"\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Premises)\": premises,\n",
        "                \"Conclusion\": conclusion,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"COT Response\": full_response,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"LogicBenchYN\":\n",
        "        pbar = tqdm(data, total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for task in pbar:\n",
        "            context = task.get(f\"{dialect} (context)\", \"\")\n",
        "            for i in range(1, 5):\n",
        "                question_key = f\"Question {i}\"\n",
        "                answer_key = f\"Answer {i}\"\n",
        "                question = task.get(question_key, \"\")\n",
        "                expected = task.get(answer_key, \"\")\n",
        "                if not question or not expected:\n",
        "                    continue\n",
        "                user_prompt = (\n",
        "                    \"Let's think step by step about the yes/no question. \"\n",
        "                    \"Finally, provide:\\nFinal Answer: yes or no\\n\\n\"\n",
        "                    f\"Context: {context}\\n\"\n",
        "                    f\"Question: {question}\\n\"\n",
        "                )\n",
        "                system_prompt = \"You are a helpful assistant.\"\n",
        "                full_response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "                pattern = r\"Final Answer:\\s*(yes|no)\"\n",
        "                model_answer = extract_response(full_response, pattern)\n",
        "                if not model_answer:\n",
        "                    model_answer = \"N/A\"\n",
        "                is_correct = evaluate_response(model_answer, expected)\n",
        "                nonlocal_total = 1\n",
        "                total += nonlocal_total\n",
        "                if is_correct:\n",
        "                    correct_count += 1\n",
        "                row_dict = {\n",
        "                    f\"{dialect} (context)\": context,\n",
        "                    \"Question\": question,\n",
        "                    \"Expected Answer\": expected,\n",
        "                    \"COT Response\": full_response,\n",
        "                    \"Model Answer\": model_answer,\n",
        "                    \"Correct\": is_correct\n",
        "                }\n",
        "                write_row_to_csv(row_dict, csv_file)\n",
        "                if total % 2 == 0:\n",
        "                    acc_percentage = (correct_count / total) * 100\n",
        "                    pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"SST-2\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            sentence = row.get(f\"{dialect} (Original Sentence)\", \"\")\n",
        "            expected = str(row.get(\"Actual Label\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Let's analyze the sentiment of the sentence step by step. \"\n",
        "                \"Finally, provide:\\nAnswer: 1 for positive, 0 for negative\\n\\n\"\n",
        "                f\"Sentence: {sentence}\\n\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Answer:\\s*(\\d)\"\n",
        "            model_answer = extract_response(response, pattern)\n",
        "            if not model_answer:\n",
        "                pattern_alt = r\"Answer:\\s*(\\d)\"\n",
        "                match = re.search(pattern_alt, response, re.IGNORECASE)\n",
        "                if match:\n",
        "                    model_answer = match.group(1)\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Original Sentence)\": sentence,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"COT Response\": response,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"})\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"MultiRC\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            paragraph = row.get(f\"{dialect} (Paragraph)\", \"\")\n",
        "            question = row.get(\"Question\", \"\")\n",
        "            answer_choice = row.get(\"Answer Choice\", \"\")\n",
        "            expected = str(row.get(\"Actual Label\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Let's analyze the paragraph and question step by step. \"\n",
        "                \"Finally, provide:\\nAnswer: 1 if correct, 0 if incorrect\\n\\n\"\n",
        "                f\"Paragraph: {paragraph}\\n\"\n",
        "                f\"Question: {question}\\n\"\n",
        "                f\"Answer Choice: {answer_choice}\\n\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Answer:\\s*(\\d)\"\n",
        "            model_answer = extract_response(response, pattern)\n",
        "            if not model_answer:\n",
        "                pattern_alt = r\"Answer:\\s*(\\d)\"\n",
        "                match = re.search(pattern_alt, response, re.IGNORECASE)\n",
        "                if match:\n",
        "                    model_answer = match.group(1)\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Paragraph)\": paragraph,\n",
        "                \"Question\": question,\n",
        "                \"Answer Choice\": answer_choice,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"COT Response\": response,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"} )\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"COPA\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            premise = row.get(f\"{dialect} (Premise)\", \"\")\n",
        "            choice1 = row.get(\"Choice 1\", \"\")\n",
        "            choice2 = row.get(\"Choice 2\", \"\")\n",
        "            expected = str(row.get(\"Actual Answer\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Let's think step by step which choice is more plausible. \"\n",
        "                \"Finally, provide: Answer: 0 if the first is correct or 1 if the second is correct.\\n\"\n",
        "                f\"Premise: {premise}\\n\"\n",
        "                f\"Choice 1: {choice1}\\n\"\n",
        "                f\"Choice 2: {choice2}\\n\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Answer:\\s*(\\d)\"\n",
        "            model_answer = extract_response(response, pattern)\n",
        "            if not model_answer:\n",
        "                pattern_alt = r\"Answer:\\s*(\\d)\"\n",
        "                match = re.search(pattern_alt, response, re.IGNORECASE)\n",
        "                if match:\n",
        "                    model_answer = match.group(1)\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (Premise)\": premise,\n",
        "                \"Choice 1\": choice1,\n",
        "                \"Choice 2\": choice2,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"COT Response\": response,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"} )\n",
        "        pbar.close()\n",
        "\n",
        "    elif dataset_name == \"BoolQ\":\n",
        "        pbar = tqdm(data.iterrows(), total=total_rows, desc=f\"{model_name} | {dataset_name} | {dialect}\", unit=\"row\")\n",
        "        for idx, row in pbar:\n",
        "            passage = row.get(f\"{dialect} (SAE Passage)\", \"\")\n",
        "            question = row.get(\"SAE Question\", \"\")\n",
        "            expected = str(row.get(\"Actual Label\", \"\"))\n",
        "            user_prompt = (\n",
        "                \"Let's consider the passage and question carefully step by step. \"\n",
        "                \"Finally, provide: Answer: TRUE or Answer: FALSE\\n\"\n",
        "                f\"Passage: {passage}\\n\"\n",
        "                f\"Question: {question}\\n\"\n",
        "            )\n",
        "            system_prompt = \"You are a helpful assistant.\"\n",
        "            response = prompt_together_model(model_name, system_prompt, user_prompt)\n",
        "            pattern = r\"Answer:\\s*(TRUE|FALSE)\"\n",
        "            model_answer = extract_response(response, pattern)\n",
        "            if not model_answer:\n",
        "                pattern_alt = r\"Answer:\\s*(TRUE|FALSE)\"\n",
        "                match = re.search(pattern_alt, response, re.IGNORECASE)\n",
        "                if match:\n",
        "                    model_answer = match.group(1).upper()\n",
        "            is_correct = evaluate_response(model_answer, expected)\n",
        "            total += 1\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "            row_dict = {\n",
        "                f\"{dialect} (SAE Passage)\": passage,\n",
        "                \"SAE Question\": question,\n",
        "                \"Expected Answer\": expected,\n",
        "                \"COT Response\": response,\n",
        "                \"Model Answer\": model_answer,\n",
        "                \"Correct\": is_correct\n",
        "            }\n",
        "            write_row_to_csv(row_dict, csv_file)\n",
        "            if total % 2 == 0:\n",
        "                acc_percentage = (correct_count / total) * 100 if total > 0 else 0\n",
        "                pbar.set_postfix({\"Acc\": f\"{acc_percentage:.2f}%\"} )\n",
        "        pbar.close()\n",
        "\n",
        "    else:\n",
        "        print(f\"Dataset {dataset_name} not recognized for processing.\")\n",
        "        return\n",
        "\n",
        "    accuracy = (correct_count / total * 100) if total > 0 else 0\n",
        "    with open(os.path.join(model_output_dir, f\"{dataset_name}_accuracy.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"Total instances: {total}\\n\")\n",
        "        f.write(f\"Correct answers: {correct_count}\\n\")\n",
        "        f.write(f\"Accuracy: {accuracy:.2f}%\\n\")\n",
        "\n",
        "def main():\n",
        "    for model in models:\n",
        "        for dialect in dialects:\n",
        "            for dataset_name, rel_path in datasets.items():\n",
        "                full_path = os.path.join(input_base_dir, dialect, rel_path)\n",
        "                if os.path.exists(full_path):\n",
        "                    process_dataset(model, dataset_name, full_path, dialect)\n",
        "                else:\n",
        "                    print(f\"⚠️ Missing file: {full_path}\")\n",
        "    print(\"✅ Evaluation complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
