{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kXo4cU_MfRNK"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install --quiet nltk rouge-score transformers torch torchvision torchaudio pandas numpy tqdm protobuf==3.20.0\n","\n","import os\n","import re\n","import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import torch\n","import torch.nn as nn\n","from transformers import BartTokenizer, BartForConditionalGeneration\n","from tqdm import tqdm\n","from rouge_score import rouge_scorer\n","import IPython\n","\n","nltk.download('punkt')\n","\n","def lexical_diversity(text):\n","    t = word_tokenize(text)\n","    return (len(set(t))/len(t)) if len(t) else 0\n","\n","def process_lexical_diversity(p, c, o):\n","    df = pd.read_csv(p)\n","    scores = []\n","    for _, x in tqdm(df[c].items(), total=len(df), desc=\"\"):\n","        scores.append(lexical_diversity(x) if isinstance(x, str) else 0)\n","    new_col = f\"LexicalDiversity ({c})\"\n","    df[new_col] = scores\n","    os.makedirs(o, exist_ok=True)\n","    base_name = os.path.splitext(os.path.basename(p))[0]\n","    out_csv = os.path.join(o, f\"{base_name}_lexical_diversity.csv\")\n","    out_txt = os.path.join(o, f\"{base_name}_average_lexical_diversity.txt\")\n","    df.to_csv(out_csv, index=False)\n","    avg_score = np.mean(scores) if len(scores) else 0\n","    with open(out_txt, \"w\") as f:\n","        f.write(f\"Average Lexical Diversity: {avg_score}\\n\")\n","\n","class BARTScorer:\n","    def __init__(self, d='cuda', m=1024, c='facebook/bart-large-cnn'):\n","        self.d = d\n","        self.m = m\n","        self.tok = BartTokenizer.from_pretrained(c)\n","        self.mod = BartForConditionalGeneration.from_pretrained(c)\n","        self.mod.eval().to(d)\n","        self.lf = nn.NLLLoss(reduction='none', ignore_index=self.mod.config.pad_token_id)\n","        self.ls = nn.LogSoftmax(dim=1)\n","\n","    def score(self, srcs, tgts, b=4):\n","        out_scores = []\n","        for i in range(0, len(srcs), b):\n","            batch_src = srcs[i:i+b]\n","            batch_tgt = tgts[i:i+b]\n","            with torch.no_grad():\n","                enc_s = self.tok(batch_src, max_length=self.m, truncation=True, padding=True, return_tensors='pt')\n","                enc_t = self.tok(batch_tgt, max_length=self.m, truncation=True, padding=True, return_tensors='pt')\n","                si = enc_s['input_ids'].to(self.d)\n","                sm = enc_s['attention_mask'].to(self.d)\n","                ti = enc_t['input_ids'].to(self.d)\n","                tm = enc_t['attention_mask'].to(self.d)\n","                tl = tm.sum(dim=1)\n","                out = self.mod(input_ids=si, attention_mask=sm, labels=ti)\n","                logits = out.logits.view(-1, self.mod.config.vocab_size)\n","                x = self.lf(self.ls(logits), ti.view(-1)).view(ti.shape[0], -1).sum(dim=1) / tl\n","                for v in x:\n","                    out_scores.append(-v.item())\n","        return out_scores\n","\n","bsc = BARTScorer('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def process_bartscore(p, c, o):\n","    df = pd.read_csv(p)\n","    if 'Original' not in df.columns or c not in df.columns:\n","        return\n","    df = df.dropna(subset=['Original', c])\n","    refs = df['Original'].astype(str).tolist()\n","    hyps = df[c].astype(str).tolist()\n","    scores = []\n","    for rr, hh in tqdm(zip(refs, hyps), total=len(refs), desc=\"\"):\n","        val = bsc.score([rr], [hh], 1)[0]\n","        scores.append(val)\n","    new_col = f\"BARTScore ({c})\"\n","    df[new_col] = scores\n","    os.makedirs(o, exist_ok=True)\n","    base_name = os.path.splitext(os.path.basename(p))[0]\n","    out_csv = os.path.join(o, f\"{base_name}_bartscore.csv\")\n","    out_txt = os.path.join(o, f\"{base_name}_bartscore.txt\")\n","    df.to_csv(out_csv, index=False)\n","    avg_score = np.mean(scores) if len(scores) else float('nan')\n","    with open(out_txt, \"w\") as f:\n","        f.write(f\"Average BARTScore: {avg_score}\\n\")\n","\n","def single_rouge(r, h):\n","    if not r or not h or pd.isna(r) or pd.isna(h):\n","        return 0\n","    sc = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True).score(r, h)\n","    return (sc[\"rouge1\"].recall + sc[\"rouge2\"].recall + sc[\"rougeL\"].recall) / 3\n","\n","def process_rouge(p, c, o):\n","    df = pd.read_csv(p)\n","    if 'Original' not in df.columns or c not in df.columns:\n","        return\n","    scores = []\n","    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"\"):\n","        scores.append(single_rouge(row['Original'], row[c]))\n","    new_col = f\"ROUGE ({c})\"\n","    df[new_col] = scores\n","    os.makedirs(o, exist_ok=True)\n","    base_name = os.path.splitext(os.path.basename(p))[0]\n","    out_csv = os.path.join(o, f\"{base_name}_rouge.csv\")\n","    out_txt = os.path.join(o, f\"{base_name}_average_rouge.txt\")\n","    df.to_csv(out_csv, index=False)\n","    avg_score = np.mean(scores) if len(scores) else 0\n","    with open(out_txt, \"w\") as f:\n","        f.write(f\"Average ROUGE: {avg_score:.4f}\\n\")\n","\n","def main():\n","    dialects = [\"AAVE\", \"IndE\", \"JamE\", \"CollSgE\"]\n","    main_files = [\n","        \"aligned_svamp700.csv\",\"aligned_mbpp374.csv\",\"aligned_logic_bench_yn500.csv\",\n","        \"aligned_logic_bench_mcq480.csv\",\"aligned_humaneval164.csv\",\"aligned_gsm8k1000.csv\",\n","        \"aligned_folio1000.csv\"\n","    ]\n","    glue_files = [\n","        \"aligned_wsc_659.csv\",\"aligned_sst-2_1000.csv\",\"aligned_multirc_1000.csv\",\n","        \"aligned_copa_500.csv\",\"aligned_boolq_1000.csv\"\n","    ]\n","    base_root = \"/content/drive/MyDrive/!!Multi-AAVENUE/Aligned Translations\"\n","    base_metrics = \"/content/drive/MyDrive/!!Multi-AAVENUE/Metrics\"\n","    modes = {\"GPT 4o\":\"Filtered GPT 4o\",\"Multi-VALUE\":\"Filtered Multi-VALUE\"}\n","\n","    def ds_name(f):\n","        if f.startswith(\"aligned_\"):\n","            f=f[8:]\n","        if f.endswith(\".csv\"):\n","            f=f[:-4]\n","        f=re.sub(r'(\\_\\d+|\\d+)$','',f)\n","        return f\n","\n","    for dialect in dialects:\n","        files = [os.path.join(base_root, dialect, x) for x in main_files]\n","        files += [os.path.join(base_root, dialect, \"GLUE + SuperGLUE\", x) for x in glue_files]\n","        for cpath in files:\n","            dataset = ds_name(os.path.basename(cpath))\n","            for mode_label, col_name in modes.items():\n","                out_bart = os.path.join(base_metrics, \"BARTScore\", mode_label, dialect, dataset)\n","                out_lex = os.path.join(base_metrics, \"Lexical Diversity\", mode_label, dialect, dataset)\n","                out_rg = os.path.join(base_metrics, \"ROUGE Score\", mode_label, dialect, dataset)\n","                try:\n","                    process_bartscore(cpath, col_name, out_bart)\n","                except:\n","                    pass\n","                try:\n","                    process_lexical_diversity(cpath, col_name, out_lex)\n","                except:\n","                    pass\n","                try:\n","                    process_rouge(cpath, col_name, out_rg)\n","                except:\n","                    pass\n","\n","    IPython.get_ipython().kernel.do_shutdown(True)\n","\n","if __name__==\"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7udVzLckduE"},"outputs":[],"source":["## Code for lexical diversity since the code above does that wrong\n","\n","from nltk.tokenize import word_tokenize\n","from nltk import download\n","import pandas as pd\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","\n","download('punkt_tab')\n","\n","def lexical_diversity(text):\n","    tokens = word_tokenize(text)\n","    total_words = len(tokens)\n","    unique_words = len(set(tokens))\n","    return (unique_words / total_words) if total_words else 0\n","\n","def process_lexical_diversity(file_path, column_name, output_dir):\n","    df = pd.read_csv(file_path)\n","    scores = []\n","\n","    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {column_name}\"):\n","        text = row[column_name] if isinstance(row[column_name], str) else \"\"\n","        scores.append(lexical_diversity(text))\n","\n","    new_col_name = f\"Lexical Diversity ({column_name})\"\n","    df[new_col_name] = scores\n","\n","    os.makedirs(output_dir, exist_ok=True)\n","    base_name = os.path.splitext(os.path.basename(file_path))[0]\n","\n","    output_csv = os.path.join(output_dir, f\"{base_name}_lexical_diversity.csv\")\n","    output_txt = os.path.join(output_dir, f\"{base_name}_average_lexical_diversity.txt\")\n","\n","    df.to_csv(output_csv, index=False)\n","\n","    avg_score = np.mean(scores) if scores else 0\n","    with open(output_txt, \"w\") as f:\n","        f.write(f\"Average Lexical Diversity: {avg_score:.4f}\\n\")\n","\n","    print(f\"Saved results for {file_path} to {output_dir}\")\n","\n","def main():\n","    dialects = [\"AAVE\", \"IndE\", \"JamE\", \"CollSgE\"]\n","    main_files = [\n","        \"aligned_svamp700.csv\", \"aligned_mbpp374.csv\", \"aligned_logic_bench_yn500.csv\",\n","        \"aligned_logic_bench_mcq480.csv\", \"aligned_humaneval164.csv\", \"aligned_gsm8k1000.csv\",\n","        \"aligned_folio1000.csv\"\n","    ]\n","    glue_files = [\n","        \"aligned_wsc_659.csv\", \"aligned_sst-2_1000.csv\", \"aligned_multirc_1000.csv\",\n","        \"aligned_copa_500.csv\", \"aligned_boolq_1000.csv\"\n","    ]\n","\n","    base_path = \"/content/drive/MyDrive/!!Multi-AAVENUE/Aligned Translations\"\n","    output_base = \"/content/drive/MyDrive/!!Multi-AAVENUE/Metrics/Lexical Diversity\"\n","\n","    modes = {\n","        \"GPT 4o\": \"Filtered GPT 4o\",\n","        \"Multi-VALUE\": \"Filtered Multi-VALUE\"\n","    }\n","\n","    for dialect in dialects:\n","        files = main_files + [os.path.join(\"GLUE + SuperGLUE\", file) for file in glue_files]\n","\n","        for file_name in files:\n","            file_path = os.path.join(base_path, dialect, file_name)\n","            dataset_name = file_name.split(\"_\")[1].split(\".\")[0] if \"_\" in file_name else file_name.split(\".\")[0]\n","\n","            for mode, column_name in modes.items():\n","                output_dir = os.path.join(output_base, mode, dialect, dataset_name)\n","\n","                try:\n","                    process_lexical_diversity(file_path, column_name, output_dir)\n","                except Exception as e:\n","                    print(f\"Error processing {file_path} for {mode}: {e}\")\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
