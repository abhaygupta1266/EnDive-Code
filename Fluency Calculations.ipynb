{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25091,"status":"ok","timestamp":1737151418952,"user":{"displayName":"abhay gupta","userId":"06781579352555862769"},"user_tz":300},"id":"z1ctJS-xmkbD","outputId":"9414c4ab-b437-4b39-bade-3ff049e56884"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WttmjnC1xmio"},"outputs":[],"source":["!pip install openai==0.28\n","\n","import os\n","import re\n","import csv\n","import pandas as pd\n","import openai\n","from tqdm import tqdm\n","\n","openai.api_key = \"API-KEY\"\n","\n","FLUENCY_PROMPT = \"\"\"\n","You are an expert linguist capable of detailed chain-of-thought reasoning.\n","\n","You are given two pieces of text:\n","1) **Original Text (SAE)** – the standard American English version.\n","2) **Dialect Text** – a translated or adapted version in the {dialect} dialect.\n","\n","Please evaluate the **Dialect Text** for:\n","1) **Fluency** in {dialect}:\n","   - Grammar, syntax, word choice, and overall naturalness in {dialect}.\n","   - Consistency, flow, and readability in {dialect}.\n","2) **Meaning Preservation**:\n","   - Does the Dialect Text retain the same meaning or intent as the Original Text (SAE)?\n","   - Are there changes or omissions that alter the meaning?\n","\n","Use the following **1–7** scoring rubric (focused on fluency, but keep meaning in mind):\n","\n","- **1**: Completely unnatural, pervasive errors, nearly unintelligible.\n","- **2**: Major issues in accuracy/naturalness, very awkward for {dialect}.\n","- **3**: Noticeable errors or unnatural phrasing, partial alignment with {dialect}.\n","- **4**: Average fluency, some issues; mostly understandable in {dialect}.\n","- **5**: Good fluency, minor errors; consistent with {dialect}.\n","- **6**: Very good fluency, rare issues; flows smoothly in {dialect}.\n","- **7**: Excellent fluency, fully natural, error-free, perfectly aligned with {dialect}.\n","\n","### INSTRUCTIONS:\n","1. Provide a **chain-of-thought** explanation comparing meaning and evaluating fluency.\n","2. End with a single line: **\"Fluency Score: X\"** (where X is an integer 1–7).\n","\n","Begin your detailed chain-of-thought analysis now.\n","\"\"\"\n","\n","def get_fluency_score(original_text: str, dialect_text: str, dialect: str) -> int:\n","    try:\n","        # Construct the user message with both the Original (SAE) and Dialect text\n","        user_content = (\n","            f\"Original Text (SAE):\\n{original_text}\\n\\n\"\n","            f\"Dialect Text ({dialect}):\\n{dialect_text}\\n\\n\"\n","            \"Provide chain-of-thought reasoning, then end with 'Fluency Score: X'.\"\n","        )\n","\n","        response = openai.ChatCompletion.create(\n","            model=\"gpt-4o\",  # or whichever GPT-4 variant you have\n","            messages=[\n","                {\"role\": \"system\", \"content\": FLUENCY_PROMPT.format(dialect=dialect)},\n","                {\"role\": \"user\", \"content\": user_content}\n","            ],\n","            temperature=0.0\n","        )\n","\n","        result_text = response[\"choices\"][0][\"message\"][\"content\"].strip()\n","\n","        # Use regex to find 'Fluency Score: X' (X is 1-7)\n","        match = re.search(r'Fluency Score:\\s*([1-7])', result_text)\n","        if match:\n","            score = int(match.group(1))\n","        else:\n","            score = -1  # If we can't parse the final line\n","\n","        return score\n","\n","    except Exception as e:\n","        print(f\"Error scoring text: {e}\")\n","        return -1  # return -1 to indicate an error\n","\n","DATASET_PATHS = [\n","    (\"FOLIO(1000)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/FOLIO(1000)/FOLIO(1000)_filtered_bleu_scores.csv\",\n","     False),\n","    (\"BoolQ (1000)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/GLUE + SuperGLUE/BoolQ (1000)/BoolQ (1000)_filtered_bleu_scores.csv\",\n","     False),\n","    (\"COPA (500)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/GLUE + SuperGLUE/COPA (500)/COPA (500)_filtered_bleu_scores.csv\",\n","     False),\n","    (\"MultiRC (1000)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/GLUE + SuperGLUE/MultiRC (1000)/MultiRC (1000)_filtered_bleu_scores.csv\",\n","     False),\n","    (\"SST-2 (1000)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/GLUE + SuperGLUE/SST-2 (1000)/SST-2 (1000)_filtered_bleu_scores.csv\",\n","     False),\n","    (\"WSC (659)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/GLUE + SuperGLUE/WSC (659)/WSC (659)_filtered_bleu_scores.csv\",\n","     False),\n","    (\"GSM8K(1000)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/GSM8K(1000)/GSM8K(1000)_filtered_bleu_scores.csv\",\n","     False),\n","    (\"HumanEVAL(164)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/HumanEVAL(164)/HumanEVAL(164)_filtered_bleu_scores.csv\",\n","     False),\n","    (\"Logic Bench MCQ(480)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/Logic Bench MCQ(480)/Logic Bench MCQ(480)_filtered_bleu_scores.csv\",\n","     True),\n","    (\"Logic Bench YN(500)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/Logic Bench YN(500)/Logic Bench YN(500)_filtered_bleu_scores.csv\",\n","     True),\n","    (\"SVAMP(700)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/SVAMP(700)/SVAMP(700)_filtered_bleu_scores.csv\",\n","     False),\n","    (\"MBPP(374)\",\n","     \"/content/drive/MyDrive/!!Multi-AAVENUE/BLEU Score Filtered Datasets/GPT 4o/AAVE/MBPP(374)/MBPP(374)_filtered_bleu_scores.csv\",\n","     False),\n","]\n","\n","DATASET_COLS = {\n","    \"FOLIO(1000)\":        (\"Premises\", \"AAVE (Premises)\"),\n","    \"BoolQ (1000)\":       (\"SAE Passage\", \"AAVE (SAE Passage)\"),\n","    \"COPA (500)\":         (\"Premise\", \"AAVE (Premise)\"),\n","    \"MultiRC (1000)\":     (\"Paragraph\", \"AAVE (Paragraph)\"),\n","    \"SST-2 (1000)\":       (\"Original Sentence\", \"AAVE (Original Sentence)\"),\n","    \"WSC (659)\":          (\"Original Paragraph\", \"AAVE (Original Paragraph)\"),\n","    \"GSM8K(1000)\":        (\"Original\", \"AAVE (Original)\"),\n","    \"HumanEVAL(164)\":     (\"Prompt\", \"AAVE (Prompt)\"),\n","    \"Logic Bench MCQ(480)\": (\"Context\", \"AAVE (context)\"),\n","    \"Logic Bench YN(500)\":  (\"Context\", \"AAVE (context)\"),\n","    \"SVAMP(700)\":         (\"Original\", \"AAVE (Original)\"),\n","    \"MBPP(374)\":          (\"Original\", \"AAVE (Original)\"),\n","}\n","\n","BASE_OUTPUT_DIR = \"/content/drive/MyDrive/!!Multi-AAVENUE/Metrics/Fluency\"\n","\n","DIALECTS = [\"AAVE\", \"ChcE\", \"CollSgE\", \"IndE\", \"JamE\"]\n","\n","def process_dataset(dialect: str, dataset_name: str, dataset_path_aave: str, is_logic_bench: bool):\n","    \"\"\"\n","    1) Build the dataset path by replacing 'AAVE' with the current dialect in the path.\n","    2) Read the CSV.\n","    3) Identify 'original_col' and 'dialect_col_template' from DATASET_COLS,\n","       then replace 'AAVE' with the actual dialect in the dialect column name.\n","    4) For each row, call get_fluency_score() to rate the translation.\n","       - Save each row's result immediately to a CSV file.\n","    5) After finishing all rows, compute and save average fluency in a .txt file.\n","    \"\"\"\n","\n","    if dataset_name == \"FOLIO(1000)\" and dialect == \"AAVE\":\n","        print(f\"Skipping FOLIO(1000) for AAVE (already done).\")\n","        return\n","\n","    dataset_path = dataset_path_aave.replace(\"AAVE\", dialect)\n","\n","    try:\n","        df = pd.read_csv(dataset_path, encoding=\"utf-8\")\n","    except FileNotFoundError:\n","        print(f\"File not found for: {dataset_path}, skipping...\")\n","        return\n","\n","    if dataset_name not in DATASET_COLS:\n","        print(f\"ERROR: No column config for dataset: {dataset_name}\")\n","        return\n","\n","    original_col, dialect_col_template = DATASET_COLS[dataset_name]\n","    dialect_col = dialect_col_template.replace(\"AAVE\", dialect)\n","\n","    if original_col not in df.columns:\n","        print(f\"WARNING: Original col '{original_col}' not found in {dataset_path}.\")\n","    if dialect_col not in df.columns:\n","        print(f\"WARNING: Dialect col '{dialect_col}' not found in {dataset_path}.\")\n","\n","    out_folder = os.path.join(BASE_OUTPUT_DIR, dialect, dataset_name)\n","    os.makedirs(out_folder, exist_ok=True)\n","    csv_out_path = os.path.join(out_folder, f\"{dataset_name}_fluency.csv\")\n","    txt_out_path = os.path.join(out_folder, f\"{dataset_name}_average_fluency.txt\")\n","\n","    all_scores = []\n","\n","    fieldnames = [\"Original Text\", f\"{dialect} Text\", \"Fluency Score\"]\n","    with open(csv_out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","        writer = csv.DictWriter(f, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","    print(f\"Processing {dataset_name} ({dialect}) - Path: {dataset_path}\")\n","    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"Scoring {dataset_name} - {dialect}\"):\n","        original_text = str(row.get(original_col, \"\"))\n","        dialect_text = str(row.get(dialect_col, \"\"))\n","\n","        if not dialect_text.strip():\n","            score = -1\n","        else:\n","            score = get_fluency_score(original_text, dialect_text, dialect)\n","\n","        all_scores.append(score)\n","\n","        with open(csv_out_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n","            writer = csv.DictWriter(f, fieldnames=fieldnames)\n","            writer.writerow({\n","                \"Original Text\": original_text,\n","                f\"{dialect} Text\": dialect_text,\n","                \"Fluency Score\": score\n","            })\n","\n","        print(f\"{dataset_name} | {dialect} | Row {i} => Score: {score}\")\n","\n","    valid_scores = [s for s in all_scores if s != -1]\n","    avg_score = sum(valid_scores) / len(valid_scores) if valid_scores else 0.0\n","    with open(txt_out_path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(f\"Average Fluency Score: {avg_score:.2f}\\n\")\n","        f.write(f\"Number of Samples: {len(valid_scores)}\\n\")\n","\n","def main():\n","    os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n","\n","    for dialect in DIALECTS:\n","        dialect_folder = os.path.join(BASE_OUTPUT_DIR, dialect)\n","        os.makedirs(dialect_folder, exist_ok=True)\n","\n","        for (ds_name, ds_path_aave, is_logic_bench) in DATASET_PATHS:\n","            process_dataset(dialect, ds_name, ds_path_aave, is_logic_bench)\n","\n","    print(\"All done! Check your output folders for results.\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNWtXIciDlrKgzZlFK/WToQ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
